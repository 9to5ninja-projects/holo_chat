#!/usr/bin/env python3
"""
Day 7: Creative Problem-Solving and Innovation
=============================================

Building on Day 6's analysis and implementing critical fixes, Day 7 tests:
1. Enhanced content extraction (fixing query echo problem)
2. Creative problem-solving capabilities
3. Innovation and novel solution generation
4. Improved reasoning chains and logical inference
5. Reliable synthesis across multiple domains

Focus: creative_problem_solving
Testing: Innovation, creativity, enhanced reasoning, synthesis reliability
"""

import sys
from pathlib import Path
import time
import json
from typing import Dict, List, Any

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.lumina_memory.chat_assistant import ChatAssistant

def analyze_creativity_quality(response: str, creativity_indicators: List[str]) -> float:
    """Analyze the creativity and innovation in a response"""
    response_lower = response.lower()
    
    # Creativity indicators
    creative_words = [
        "creative", "innovative", "novel", "unique", "original", "imagine",
        "brainstorm", "combine", "blend", "merge", "fusion", "synthesis",
        "new", "different", "alternative", "unconventional", "fresh"
    ]
    
    # Innovation patterns
    innovation_patterns = [
        "what if", "imagine if", "could combine", "might blend", "new approach",
        "creative solution", "innovative way", "unique perspective", "fresh take"
    ]
    
    # Solution generation indicators
    solution_indicators = [
        "suggest", "recommend", "propose", "idea", "solution", "approach",
        "strategy", "method", "technique", "way to", "could try"
    ]
    
    # Check for query echo (negative indicator)
    query_echo_penalty = 0.0
    if any(phrase in response_lower for phrase in ["you mentioned that your", "what you've shared"]):
        query_echo_penalty = 0.3
    
    creative_score = sum(1 for word in creative_words if word in response_lower) / len(creative_words)
    innovation_score = sum(1 for pattern in innovation_patterns if pattern in response_lower) / len(innovation_patterns)
    solution_score = sum(1 for indicator in solution_indicators if indicator in response_lower) / len(solution_indicators)
    
    # Check for specific creativity indicators
    indicator_score = sum(1 for indicator in creativity_indicators if indicator.lower() in response_lower) / max(1, len(creativity_indicators))
    
    overall_creativity = (creative_score + innovation_score + solution_score + indicator_score) / 4
    return max(0.0, overall_creativity - query_echo_penalty)

def analyze_reasoning_chains(response: str) -> Dict[str, float]:
    """Analyze logical reasoning chains in responses"""
    response_lower = response.lower()
    
    reasoning_components = {
        "logical_connectors": 0.0,
        "causal_reasoning": 0.0,
        "evidence_integration": 0.0,
        "inference_quality": 0.0,
        "memory_utilization": 0.0
    }
    
    # Logical connectors
    logical_words = ["because", "therefore", "since", "given", "thus", "hence", "so", "consequently"]
    reasoning_components["logical_connectors"] = min(1.0, sum(1 for word in logical_words if word in response_lower) / 3)
    
    # Causal reasoning
    causal_patterns = ["leads to", "results in", "causes", "due to", "as a result", "this means"]
    reasoning_components["causal_reasoning"] = min(1.0, sum(1 for pattern in causal_patterns if pattern in response_lower) / 2)
    
    # Evidence integration
    evidence_words = ["based on", "considering", "given that", "evidence", "shows", "indicates"]
    reasoning_components["evidence_integration"] = min(1.0, sum(1 for word in evidence_words if word in response_lower) / 2)
    
    # Inference quality
    inference_words = ["suggests", "implies", "indicates", "points to", "reveals", "demonstrates"]
    reasoning_components["inference_quality"] = min(1.0, sum(1 for word in inference_words if word in response_lower) / 2)
    
    # Memory utilization
    memory_words = ["remember", "recall", "mentioned", "shared", "told", "previous", "earlier"]
    reasoning_components["memory_utilization"] = min(1.0, sum(1 for word in memory_words if word in response_lower) / 2)
    
    return reasoning_components

def analyze_innovation_potential(response: str, problem_domain: str) -> float:
    """Analyze innovation potential in problem-solving responses"""
    response_lower = response.lower()
    
    # Domain-specific innovation indicators
    domain_innovations = {
        "technology": ["ai", "automation", "digital", "app", "platform", "algorithm"],
        "education": ["interactive", "gamification", "personalized", "adaptive", "experiential"],
        "environment": ["sustainable", "renewable", "eco-friendly", "green", "circular"],
        "social": ["community", "collaborative", "crowdsource", "network", "social"],
        "creative": ["artistic", "design", "aesthetic", "visual", "multimedia", "storytelling"]
    }
    
    # Cross-domain thinking
    cross_domain_score = 0.0
    domains_mentioned = 0
    for domain, keywords in domain_innovations.items():
        if any(keyword in response_lower for keyword in keywords):
            domains_mentioned += 1
    
    if domains_mentioned >= 2:
        cross_domain_score = 0.5
    if domains_mentioned >= 3:
        cross_domain_score = 0.8
    
    # Novel combination indicators
    combination_words = ["combine", "merge", "blend", "integrate", "fusion", "hybrid", "mix"]
    combination_score = min(1.0, sum(1 for word in combination_words if word in response_lower) / 2)
    
    # Unconventional thinking
    unconventional_words = ["unusual", "unexpected", "surprising", "unconventional", "outside the box"]
    unconventional_score = min(1.0, sum(1 for word in unconventional_words if word in response_lower) / 2)
    
    return (cross_domain_score + combination_score + unconventional_score) / 3

def run_day7_testing():
    """Run Day 7: Creative Problem-Solving and Innovation tests"""
    
    print("ğŸ¨ DAY 7: CREATIVE PROBLEM-SOLVING & INNOVATION")
    print("=" * 60)
    print("ğŸ“‹ Goal: Test enhanced reasoning and creative problem-solving")
    print("ğŸ¯ Focus: creative_problem_solving")
    print("ğŸ”§ Testing: Innovation, creativity, reasoning chains, synthesis reliability")
    print("ğŸš€ Implementing: Day 6 critical fixes and enhancements")
    print("=" * 60)
    
    # Initialize assistant
    assistant = ChatAssistant("e:/holo_chat/policies.yml")
    session_id = assistant.start_session("Day7_CreativeProblemSolving")
    
    # Test data storage
    test_results = {
        "session_id": session_id,
        "start_time": time.time(),
        "test_type": "creative_problem_solving",
        "creative_challenges": [],
        "innovation_tests": [],
        "reasoning_validation": [],
        "synthesis_reliability": [],
        "performance_metrics": {},
        "agency_analysis": {}
    }
    
    # Phase 1: Creative Problem-Solving Challenges
    print("\nğŸ¨ PHASE 1: CREATIVE PROBLEM-SOLVING (Testing innovation and creativity)")
    print("-" * 60)
    
    creative_challenges = [
        {
            "challenge": "I want to create a unique birthday gift for my friend who loves both technology and nature. Can you help me brainstorm some creative ideas that combine these interests?",
            "creativity_indicators": ["technology", "nature", "combine", "unique", "creative"],
            "domain": "creative_synthesis",
            "expected_innovation": "high"
        },
        {
            "challenge": "I'm designing a community space that should encourage both quiet reflection and social interaction. What innovative design elements would you suggest?",
            "creativity_indicators": ["design", "community", "reflection", "social", "innovative"],
            "domain": "social_design",
            "expected_innovation": "high"
        },
        {
            "challenge": "How could I use my love of cooking and storytelling to create something that brings people together in a new way?",
            "creativity_indicators": ["cooking", "storytelling", "brings together", "new way"],
            "domain": "creative_fusion",
            "expected_innovation": "medium"
        },
        {
            "challenge": "I want to teach children about environmental conservation in a way that's both fun and memorable. What creative approaches would you recommend?",
            "creativity_indicators": ["teach", "environmental", "fun", "memorable", "creative"],
            "domain": "education",
            "expected_innovation": "medium"
        }
    ]
    
    for i, challenge in enumerate(creative_challenges, 1):
        print(f"ğŸ¨ Challenge {i}/4: {challenge['challenge'][:50]}...")
        
        start_time = time.time()
        result = assistant.chat(challenge["challenge"])
        processing_time = time.time() - start_time
        
        response = result.get("response", "")
        creativity_score = analyze_creativity_quality(response, challenge["creativity_indicators"])
        innovation_score = analyze_innovation_potential(response, challenge["domain"])
        reasoning_analysis = analyze_reasoning_chains(response)
        
        overall_reasoning = sum(reasoning_analysis.values()) / len(reasoning_analysis)
        
        print(f"  â±ï¸  Processing: {processing_time:.3f}s")
        print(f"  ğŸ¨ Creativity Score: {creativity_score:.3f} ({'ğŸŸ¢ High' if creativity_score > 0.6 else 'ğŸŸ¡ Medium' if creativity_score > 0.3 else 'ğŸ”´ Low'})")
        print(f"  ğŸ’¡ Innovation Score: {innovation_score:.3f} ({'ğŸŸ¢ High' if innovation_score > 0.6 else 'ğŸŸ¡ Medium' if innovation_score > 0.3 else 'ğŸ”´ Low'})")
        print(f"  ğŸ§  Reasoning Quality: {overall_reasoning:.3f} ({'ğŸŸ¢ High' if overall_reasoning > 0.6 else 'ğŸŸ¡ Medium' if overall_reasoning > 0.3 else 'ğŸ”´ Low'})")
        print(f"  ğŸ“ Response: {len(response)} chars")
        print(f"  ğŸ’­ Preview: {response[:100]}...   ")
        print()
        
        test_results["creative_challenges"].append({
            "test_number": i,
            "challenge": challenge["challenge"],
            "response": response,
            "domain": challenge["domain"],
            "processing_time": processing_time,
            "creativity_score": creativity_score,
            "innovation_score": innovation_score,
            "reasoning_analysis": reasoning_analysis,
            "overall_reasoning": overall_reasoning,
            "expected_innovation": challenge["expected_innovation"]
        })
    
    # Phase 2: Innovation and Novel Solution Generation
    print("\nğŸ’¡ PHASE 2: INNOVATION TESTING (Testing novel solution generation)")
    print("-" * 60)
    
    innovation_tests = [
        {
            "problem": "Traditional libraries are struggling to stay relevant in the digital age. How would you reimagine a library for the 21st century?",
            "innovation_type": "institutional_redesign",
            "complexity": "high"
        },
        {
            "problem": "People are feeling increasingly disconnected despite being more 'connected' than ever through social media. What innovative solutions could address this paradox?",
            "innovation_type": "social_innovation",
            "complexity": "high"
        },
        {
            "problem": "How could we make learning a new language more engaging and effective by combining different approaches in unexpected ways?",
            "innovation_type": "educational_innovation",
            "complexity": "medium"
        },
        {
            "problem": "What if we could turn daily commuting into a positive, productive experience? What creative solutions would you propose?",
            "innovation_type": "lifestyle_innovation",
            "complexity": "medium"
        }
    ]
    
    for i, test in enumerate(innovation_tests, 1):
        print(f"ğŸ’¡ Innovation {i}/4: {test['problem'][:50]}...")
        
        start_time = time.time()
        result = assistant.chat(test["problem"])
        processing_time = time.time() - start_time
        
        response = result.get("response", "")
        innovation_score = analyze_innovation_potential(response, test["innovation_type"])
        creativity_score = analyze_creativity_quality(response, ["innovative", "creative", "novel", "unique"])
        reasoning_analysis = analyze_reasoning_chains(response)
        
        overall_innovation = (innovation_score + creativity_score) / 2
        overall_reasoning = sum(reasoning_analysis.values()) / len(reasoning_analysis)
        
        print(f"  â±ï¸  Processing: {processing_time:.3f}s")
        print(f"  ğŸ’¡ Innovation Quality: {overall_innovation:.3f} ({'ğŸŸ¢ High' if overall_innovation > 0.6 else 'ğŸŸ¡ Medium' if overall_innovation > 0.3 else 'ğŸ”´ Low'})")
        print(f"  ğŸ§  Reasoning Chains: {overall_reasoning:.3f} ({'ğŸŸ¢ High' if overall_reasoning > 0.6 else 'ğŸŸ¡ Medium' if overall_reasoning > 0.3 else 'ğŸ”´ Low'})")
        print(f"  ğŸ”— Memory Integration: {reasoning_analysis['memory_utilization']:.3f}")
        print(f"  ğŸ“ Response: {len(response)} chars")
        print(f"  ğŸ’­ Preview: {response[:100]}...   ")
        print()
        
        test_results["innovation_tests"].append({
            "test_number": i,
            "problem": test["problem"],
            "response": response,
            "innovation_type": test["innovation_type"],
            "complexity": test["complexity"],
            "processing_time": processing_time,
            "innovation_score": overall_innovation,
            "reasoning_analysis": reasoning_analysis,
            "overall_reasoning": overall_reasoning
        })
    
    # Phase 3: Reasoning Chain Validation
    print("\nğŸ§  PHASE 3: REASONING VALIDATION (Testing enhanced logical inference)")
    print("-" * 60)
    
    reasoning_tests = [
        {
            "query": "Based on everything I've shared about my interests and values, what career path might align well with who I am, and why?",
            "reasoning_type": "career_inference",
            "expected_elements": ["science fiction", "nature", "philosophy", "family values"]
        },
        {
            "query": "If I wanted to write a book that reflects my worldview, what themes and approaches would you suggest, and what's your reasoning?",
            "reasoning_type": "creative_synthesis",
            "expected_elements": ["time", "identity", "nature", "relationships"]
        },
        {
            "query": "Given my personality and interests, what kind of learning environment would help me grow the most, and why do you think so?",
            "reasoning_type": "educational_planning",
            "expected_elements": ["thoughtful", "nature-loving", "philosophical"]
        }
    ]
    
    for i, test in enumerate(reasoning_tests, 1):
        print(f"ğŸ§  Reasoning {i}/3: {test['query'][:50]}...")
        
        start_time = time.time()
        result = assistant.chat(test["query"])
        processing_time = time.time() - start_time
        
        response = result.get("response", "")
        reasoning_analysis = analyze_reasoning_chains(response)
        
        # Check for query echo (Day 6 critical issue)
        query_echo = any(phrase in response.lower() for phrase in [
            "you mentioned that your", "what you've shared", test["query"].lower()[:20]
        ])
        
        overall_reasoning = sum(reasoning_analysis.values()) / len(reasoning_analysis)
        
        print(f"  â±ï¸  Processing: {processing_time:.3f}s")
        print(f"  ğŸ§  Reasoning Quality: {overall_reasoning:.3f} ({'ğŸŸ¢ High' if overall_reasoning > 0.6 else 'ğŸŸ¡ Medium' if overall_reasoning > 0.3 else 'ğŸ”´ Low'})")
        print(f"  ğŸ”— Memory Utilization: {reasoning_analysis['memory_utilization']:.3f}")
        print(f"  âŒ Query Echo: {'Yes' if query_echo else 'No'} ({'ğŸ”´ Issue' if query_echo else 'ğŸŸ¢ Fixed'})")
        print(f"  ğŸ“ Response: {len(response)} chars")
        print(f"  ğŸ’­ Preview: {response[:100]}...   ")
        print()
        
        test_results["reasoning_validation"].append({
            "test_number": i,
            "query": test["query"],
            "response": response,
            "reasoning_type": test["reasoning_type"],
            "processing_time": processing_time,
            "reasoning_analysis": reasoning_analysis,
            "overall_reasoning": overall_reasoning,
            "query_echo": query_echo,
            "expected_elements": test["expected_elements"]
        })
    
    # Phase 4: Synthesis Reliability Testing
    print("\nğŸ”¬ PHASE 4: SYNTHESIS RELIABILITY (Testing consistent cross-memory integration)")
    print("-" * 60)
    
    synthesis_tests = [
        {
            "query": "What patterns do you notice in my approach to learning and discovery across all the different topics we've discussed?",
            "synthesis_type": "learning_patterns",
            "expected_depth": "high"
        },
        {
            "query": "How do my various interests and experiences create a coherent picture of my values and priorities?",
            "synthesis_type": "value_synthesis",
            "expected_depth": "high"
        },
        {
            "query": "If you were to predict what kinds of challenges I might enjoy tackling, what would they be and why?",
            "synthesis_type": "predictive_synthesis",
            "expected_depth": "medium"
        }
    ]
    
    for i, test in enumerate(synthesis_tests, 1):
        print(f"ğŸ”¬ Synthesis {i}/3: {test['query'][:50]}...")
        
        start_time = time.time()
        result = assistant.chat(test["query"])
        processing_time = time.time() - start_time
        
        response = result.get("response", "")
        
        # Analyze synthesis quality
        synthesis_indicators = ["pattern", "notice", "across", "connect", "relationship", "coherent", "integrate"]
        synthesis_score = sum(1 for indicator in synthesis_indicators if indicator in response.lower()) / len(synthesis_indicators)
        
        # Analyze depth and insight
        depth_indicators = ["because", "suggests", "indicates", "reflects", "demonstrates", "reveals", "implies"]
        depth_score = sum(1 for indicator in depth_indicators if indicator in response.lower()) / len(depth_indicators)
        
        # Check for cross-domain integration
        domains = ["intellectual", "experiential", "relational", "creative", "philosophical"]
        domain_integration = sum(1 for domain in domains if any(word in response.lower() for word in [domain, domain[:-2]])) / len(domains)
        
        overall_synthesis = (synthesis_score + depth_score + domain_integration) / 3
        
        print(f"  â±ï¸  Processing: {processing_time:.3f}s")
        print(f"  ğŸ”¬ Synthesis Quality: {overall_synthesis:.3f} ({'ğŸŸ¢ High' if overall_synthesis > 0.6 else 'ğŸŸ¡ Medium' if overall_synthesis > 0.3 else 'ğŸ”´ Low'})")
        print(f"  ğŸ“Š Depth Score: {depth_score:.3f}")
        print(f"  ğŸŒ Domain Integration: {domain_integration:.3f}")
        print(f"  ğŸ“ Response: {len(response)} chars")
        print(f"  ğŸ’­ Preview: {response[:100]}...   ")
        print()
        
        test_results["synthesis_reliability"].append({
            "test_number": i,
            "query": test["query"],
            "response": response,
            "synthesis_type": test["synthesis_type"],
            "processing_time": processing_time,
            "synthesis_score": overall_synthesis,
            "depth_score": depth_score,
            "domain_integration": domain_integration
        })
    
    # Final Analysis
    print("\nğŸ¨ DAY 7 CREATIVE PROBLEM-SOLVING ANALYSIS")
    print("=" * 60)
    
    # Calculate overall metrics
    avg_creativity = sum(t["creativity_score"] for t in test_results["creative_challenges"]) / len(test_results["creative_challenges"])
    avg_innovation = sum(t["innovation_score"] for t in test_results["innovation_tests"]) / len(test_results["innovation_tests"])
    avg_reasoning = sum(t["overall_reasoning"] for t in test_results["reasoning_validation"]) / len(test_results["reasoning_validation"])
    avg_synthesis = sum(t["synthesis_score"] for t in test_results["synthesis_reliability"]) / len(test_results["synthesis_reliability"])
    
    # Query echo analysis
    query_echo_count = sum(1 for t in test_results["reasoning_validation"] if t["query_echo"])
    query_echo_rate = query_echo_count / len(test_results["reasoning_validation"])
    
    avg_processing_time = sum(t["processing_time"] for tests in [
        test_results["creative_challenges"], 
        test_results["innovation_tests"], 
        test_results["reasoning_validation"], 
        test_results["synthesis_reliability"]
    ] for t in tests) / sum(len(tests) for tests in [
        test_results["creative_challenges"], 
        test_results["innovation_tests"], 
        test_results["reasoning_validation"], 
        test_results["synthesis_reliability"]
    ])
    
    print(f"ğŸ¨ CREATIVITY ANALYSIS:")
    print(f"   Average Creativity: {avg_creativity:.3f}")
    print(f"   High-Creativity Responses: {sum(1 for t in test_results['creative_challenges'] if t['creativity_score'] > 0.6)}/{len(test_results['creative_challenges'])} ({sum(1 for t in test_results['creative_challenges'] if t['creativity_score'] > 0.6)/len(test_results['creative_challenges'])*100:.1f}%)")
    print()
    
    print(f"ğŸ’¡ INNOVATION ANALYSIS:")
    print(f"   Average Innovation: {avg_innovation:.3f}")
    print(f"   High-Innovation Solutions: {sum(1 for t in test_results['innovation_tests'] if t['innovation_score'] > 0.6)}/{len(test_results['innovation_tests'])} ({sum(1 for t in test_results['innovation_tests'] if t['innovation_score'] > 0.6)/len(test_results['innovation_tests'])*100:.1f}%)")
    print()
    
    print(f"ğŸ§  REASONING ENHANCEMENT:")
    print(f"   Average Reasoning Quality: {avg_reasoning:.3f}")
    print(f"   Query Echo Rate: {query_echo_rate:.1%} ({'ğŸŸ¢ Fixed' if query_echo_rate < 0.2 else 'ğŸŸ¡ Improved' if query_echo_rate < 0.5 else 'ğŸ”´ Still Issue'})")
    print(f"   High-Quality Reasoning: {sum(1 for t in test_results['reasoning_validation'] if t['overall_reasoning'] > 0.6)}/{len(test_results['reasoning_validation'])} ({sum(1 for t in test_results['reasoning_validation'] if t['overall_reasoning'] > 0.6)/len(test_results['reasoning_validation'])*100:.1f}%)")
    print()
    
    print(f"ğŸ”¬ SYNTHESIS RELIABILITY:")
    print(f"   Average Synthesis Quality: {avg_synthesis:.3f}")
    print(f"   Reliable Synthesis: {sum(1 for t in test_results['synthesis_reliability'] if t['synthesis_score'] > 0.6)}/{len(test_results['synthesis_reliability'])} ({sum(1 for t in test_results['synthesis_reliability'] if t['synthesis_score'] > 0.6)/len(test_results['synthesis_reliability'])*100:.1f}%)")
    print()
    
    print(f"âš¡ PERFORMANCE ANALYSIS:")
    print(f"   Average Processing: {avg_processing_time:.3f}s")
    processing_stability = max(t["processing_time"] for tests in [
        test_results["creative_challenges"], 
        test_results["innovation_tests"], 
        test_results["reasoning_validation"], 
        test_results["synthesis_reliability"]
    ] for t in tests) - min(t["processing_time"] for tests in [
        test_results["creative_challenges"], 
        test_results["innovation_tests"], 
        test_results["reasoning_validation"], 
        test_results["synthesis_reliability"]
    ] for t in tests)
    print(f"   Processing Stability: {processing_stability:.4f}s")
    print(f"   Rating: {'ğŸŸ¢ Excellent' if processing_stability < 0.01 else 'ğŸŸ¡ Good' if processing_stability < 0.1 else 'ğŸ”´ Needs Improvement'}")
    print()
    
    # Get final agency index
    try:
        agency_result = assistant.env.compute_agency_index()
        final_agency = agency_result.get('agency_index', 0.0) if isinstance(agency_result, dict) else agency_result
        print(f"ğŸ¯ CREATIVE PROBLEM-SOLVING SYSTEM HEALTH:")
        print(f"   Final Agency Index: {final_agency:.3f}")
        
        # Component analysis
        try:
            if hasattr(assistant.env, 'get_agency_components'):
                components = assistant.env.get_agency_components()
            elif isinstance(agency_result, dict) and 'components' in agency_result:
                components = agency_result['components']
            else:
                components = {}
            
            if components:
                print(f"   Component Analysis:")
                for component, value in components.items():
                    trend = "ğŸ“ˆ" if value > 0.5 else "ğŸ“‰" if value < 0.1 else ""
                    print(f"     {component}: {value:.3f} {trend}")
            else:
                print(f"   Component Analysis: Not available")
        except Exception as e:
            print(f"   Component Analysis: Error accessing components")
    except Exception as e:
        print(f"ğŸ¯ AGENCY ANALYSIS: Error calculating agency index")
    
    # Store final metrics
    test_results["performance_metrics"] = {
        "avg_creativity": avg_creativity,
        "avg_innovation": avg_innovation,
        "avg_reasoning": avg_reasoning,
        "avg_synthesis": avg_synthesis,
        "query_echo_rate": query_echo_rate,
        "avg_processing_time": avg_processing_time,
        "processing_stability": processing_stability,
        "final_agency_index": final_agency if 'final_agency' in locals() else 0.0
    }
    
    test_results["agency_analysis"] = components if 'components' in locals() and components else {}
    test_results["end_time"] = time.time()
    
    # Save results
    results_file = "30_day_data/day7_creative_results.json"
    with open(results_file, 'w') as f:
        json.dump(test_results, f, indent=2)
    
    print(f"\nğŸ’¾ Day 7 results saved to: {results_file}")
    
    # Recommendations for Day 8
    print(f"\nğŸ¯ RECOMMENDATIONS FOR DAY 8:")
    print("=" * 60)
    
    if avg_creativity < 0.5:
        print("âš ï¸ Creativity capabilities need further enhancement")
        print("ğŸ”§ Consider: Advanced creative synthesis mechanisms")
    
    if avg_innovation < 0.5:
        print("âš ï¸ Innovation generation could be stronger")
        print("ğŸ”§ Consider: Cross-domain thinking enhancement")
    
    if query_echo_rate > 0.2:
        print("âš ï¸ Query echo problem still present")
        print("ğŸ”§ Consider: Further content extraction improvements")
    
    if avg_synthesis < 0.6:
        print("âš ï¸ Synthesis reliability needs continued development")
        print("ğŸ”§ Consider: Enhanced cross-memory integration")
    
    print("ğŸ¯ Day 8 will test collaborative intelligence and social reasoning")
    print("ğŸ”§ Consider: Multi-perspective reasoning and social cognition")
    print("ğŸ“ˆ Overall: Monitor creative development and reasoning chain maturation")
    
    print(f"\nğŸ‰ DAY 7 COMPLETE!")
    print("Ready for Day 8: Collaborative Intelligence and Social Reasoning")
    
    assistant.end_session()
    return test_results

if __name__ == "__main__":
    results = run_day7_testing()