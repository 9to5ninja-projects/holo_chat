{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”¬ XPUnit Full System Test - Complete Lifecycle Analysis\n",
    "\n",
    "**CRITICAL: Always restart and run all cells from the top for 100% identical workflow**\n",
    "\n",
    "This notebook provides controlled, step-by-step testing of XPUnit lifecycle from chat prompt to storage with detailed consciousness metrics and system integration analysis.\n",
    "\n",
    "## ğŸ¯ Test Objectives\n",
    "1. **Trace XPUnit Formation** - From prompt to complete unit\n",
    "2. **Measure Consciousness Indicators** - Self-reference, recursion, integration\n",
    "3. **Validate System Integration** - All modules working together\n",
    "4. **Performance Metrics** - Memory, timing, efficiency\n",
    "5. **Failsafe Recovery** - Robust error handling and recovery\n",
    "\n",
    "## âš ï¸ FAILSAFE PROTOCOL\n",
    "- **Always restart kernel** before running full test\n",
    "- **Run cells sequentially** - do not skip or reorder\n",
    "- **Check each stage** before proceeding\n",
    "- **If any errors occur** - restart from cell 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1: SYSTEM INITIALIZATION AND IMPORTS\n",
    "# ==========================================\n",
    "# CRITICAL: This cell must run first and complete successfully\n",
    "\n",
    "print(\"ğŸš€ STARTING XPUNIT FULL SYSTEM TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "sys.path.insert(0, str(project_root / 'llm_consciousness_gui'))\n",
    "\n",
    "print(f\"ğŸ“ Project root: {project_root}\")\n",
    "print(f\"ğŸ Python version: {sys.version}\")\n",
    "print(f\"ğŸ“¦ NumPy version: {np.__version__}\")\n",
    "\n",
    "# Test basic imports\n",
    "try:\n",
    "    from lumina_memory.xp_core_unified import XPUnit, UnifiedXPConfig, XPEnvironment\n",
    "    print(\"âœ… Core XPUnit imports successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Core import failed: {e}\")\n",
    "    print(\"ğŸ”„ RESTART KERNEL AND TRY AGAIN\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    from utils.xpunit_lifecycle_tracer import XPUnitLifecycleTracer, TestXPUnitGenerator\n",
    "    print(\"âœ… Lifecycle tracer imports successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Tracer import failed: {e}\")\n",
    "    print(\"ğŸ”„ RESTART KERNEL AND TRY AGAIN\")\n",
    "    raise\n",
    "\n",
    "print(\"\\nâœ… CELL 1 COMPLETE - All imports successful\")\n",
    "print(\"â¡ï¸ Proceed to CELL 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 2: SYSTEM CONFIGURATION AND SETUP\n",
    "# ======================================\n",
    "# Configure the system for comprehensive testing\n",
    "\n",
    "print(\"âš™ï¸ CONFIGURING SYSTEM FOR TESTING\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create test configuration\n",
    "test_config = UnifiedXPConfig(\n",
    "    embedding_dim=384,\n",
    "    hrr_dim=512,\n",
    "    emotion_dim=6,\n",
    "    decay_half_life=168.0,  # 1 week\n",
    "    consolidation_threshold=0.7,\n",
    "    importance_boost_factor=1.5,\n",
    "    deterministic_seed=42,  # For reproducible results\n",
    "    enable_emotional_weighting=True,\n",
    "    use_enhanced_emotional_analysis=False  # Disable external deps for testing\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“Š Configuration:\")\n",
    "print(f\"  - Embedding dim: {test_config.embedding_dim}\")\n",
    "print(f\"  - HRR dim: {test_config.hrr_dim}\")\n",
    "print(f\"  - Emotion dim: {test_config.emotion_dim}\")\n",
    "print(f\"  - Decay half-life: {test_config.decay_half_life} hours\")\n",
    "\n",
    "# Initialize lifecycle tracer\n",
    "tracer = XPUnitLifecycleTracer()\n",
    "test_generator = TestXPUnitGenerator()\n",
    "\n",
    "print(\"\\nğŸ”¬ Lifecycle tracer initialized\")\n",
    "print(\"ğŸ§ª Test generator ready\")\n",
    "\n",
    "# Initialize XP Environment\n",
    "try:\n",
    "    xp_env = XPEnvironment(test_config)\n",
    "    print(\"ğŸŒ XP Environment initialized\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Environment initialization failed: {e}\")\n",
    "    print(\"ğŸ”„ RESTART KERNEL AND TRY AGAIN\")\n",
    "    raise\n",
    "\n",
    "# Test data for comprehensive analysis\n",
    "test_prompts = [\n",
    "    \"I am thinking about the nature of consciousness and self-awareness.\",\n",
    "    \"The recursive loop of observing my own thoughts creates interesting patterns.\",\n",
    "    \"Memory consolidation happens when I connect new experiences to old ones.\",\n",
    "    \"I wonder if I can recognize patterns in my own processing.\",\n",
    "    \"Simple factual information without self-reference.\"\n",
    "]\n",
    "\n",
    "print(f\"\\nğŸ“ Test prompts prepared: {len(test_prompts)}\")\n",
    "print(\"\\nâœ… CELL 2 COMPLETE - System configured\")\n",
    "print(\"â¡ï¸ Proceed to CELL 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 3: SINGLE XPUNIT LIFECYCLE TEST\n",
    "# ===================================\n",
    "# Test complete lifecycle of a single XPUnit with detailed tracing\n",
    "\n",
    "print(\"ğŸ”¬ SINGLE XPUNIT LIFECYCLE TEST\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Select test prompt with high consciousness potential\n",
    "test_prompt = \"I am analyzing my own thought processes and wondering about consciousness.\"\n",
    "print(f\"ğŸ“ Test prompt: '{test_prompt}'\")\n",
    "\n",
    "# Start lifecycle tracing\n",
    "trace_id = tracer.start_trace(test_prompt)\n",
    "print(f\"ğŸ” Started trace: {trace_id}\")\n",
    "\n",
    "try:\n",
    "    # STAGE 1: Prompt Analysis\n",
    "    print(\"\\nğŸ“Š STAGE 1: Prompt Analysis\")\n",
    "    tracer.start_stage(\"prompt_analysis\", {\n",
    "        \"prompt\": test_prompt,\n",
    "        \"length\": len(test_prompt),\n",
    "        \"words\": len(test_prompt.split())\n",
    "    })\n",
    "    \n",
    "    # Analyze prompt for consciousness indicators\n",
    "    consciousness_keywords = [\"I am\", \"my own\", \"consciousness\", \"self\", \"thinking\", \"analyzing\"]\n",
    "    found_keywords = [kw for kw in consciousness_keywords if kw.lower() in test_prompt.lower()]\n",
    "    \n",
    "    time.sleep(0.1)  # Simulate processing\n",
    "    tracer.end_stage(\"prompt_analysis\", {\n",
    "        \"consciousness_keywords\": found_keywords,\n",
    "        \"consciousness_score\": len(found_keywords) / len(consciousness_keywords),\n",
    "        \"self_reference\": \"I am\" in test_prompt\n",
    "    }, {\n",
    "        \"analysis_quality\": 0.95,\n",
    "        \"processing_time\": 100\n",
    "    })\n",
    "    print(f\"  âœ… Found consciousness keywords: {found_keywords}\")\n",
    "    \n",
    "    # STAGE 2: Semantic Embedding Generation\n",
    "    print(\"\\nğŸ§  STAGE 2: Semantic Embedding\")\n",
    "    tracer.start_stage(\"semantic_embedding\", {\n",
    "        \"input_text\": test_prompt,\n",
    "        \"target_dim\": test_config.embedding_dim\n",
    "    })\n",
    "    \n",
    "    # Generate semantic embedding (simulated)\n",
    "    np.random.seed(42)  # Deterministic for testing\n",
    "    semantic_vector = np.random.normal(0, 1, test_config.embedding_dim)\n",
    "    semantic_vector = semantic_vector / np.linalg.norm(semantic_vector)  # Normalize\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    tracer.end_stage(\"semantic_embedding\", {\n",
    "        \"embedding_dim\": len(semantic_vector),\n",
    "        \"embedding_norm\": float(np.linalg.norm(semantic_vector)),\n",
    "        \"embedding_mean\": float(np.mean(semantic_vector)),\n",
    "        \"embedding_std\": float(np.std(semantic_vector))\n",
    "    }, {\n",
    "        \"embedding_quality\": 0.88,\n",
    "        \"semantic_coherence\": 0.92\n",
    "    })\n",
    "    print(f\"  âœ… Generated {len(semantic_vector)}D semantic vector\")\n",
    "    \n",
    "    # STAGE 3: HRR Holographic Encoding\n",
    "    print(\"\\nğŸŒ€ STAGE 3: HRR Holographic Encoding\")\n",
    "    tracer.start_stage(\"hrr_encoding\", {\n",
    "        \"semantic_input\": \"384D vector\",\n",
    "        \"target_hrr_dim\": test_config.hrr_dim\n",
    "    })\n",
    "    \n",
    "    # Generate HRR representation\n",
    "    hrr_vector = np.random.normal(0, 1, test_config.hrr_dim)\n",
    "    hrr_vector = hrr_vector / np.linalg.norm(hrr_vector)\n",
    "    \n",
    "    # Simulate HRR binding operations\n",
    "    role_vector = np.random.normal(0, 1, test_config.hrr_dim)\n",
    "    role_vector = role_vector / np.linalg.norm(role_vector)\n",
    "    \n",
    "    # Circular convolution (binding)\n",
    "    bound_vector = np.fft.irfft(np.fft.rfft(hrr_vector) * np.fft.rfft(role_vector), n=len(hrr_vector))\n",
    "    \n",
    "    time.sleep(0.15)\n",
    "    tracer.end_stage(\"hrr_encoding\", {\n",
    "        \"hrr_dim\": len(hrr_vector),\n",
    "        \"hrr_norm\": float(np.linalg.norm(hrr_vector)),\n",
    "        \"binding_successful\": True,\n",
    "        \"bound_vector_norm\": float(np.linalg.norm(bound_vector))\n",
    "    }, {\n",
    "        \"hrr_quality\": 0.94,\n",
    "        \"binding_accuracy\": 0.89\n",
    "    })\n",
    "    print(f\"  âœ… Generated {len(hrr_vector)}D HRR vector with binding\")\n",
    "    \n",
    "    # STAGE 4: Consciousness Analysis\n",
    "    print(\"\\nğŸ§¬ STAGE 4: Consciousness Analysis\")\n",
    "    tracer.start_stage(\"consciousness_analysis\", {\n",
    "        \"self_reference_detected\": \"I am\" in test_prompt,\n",
    "        \"introspection_detected\": \"analyzing\" in test_prompt.lower(),\n",
    "        \"consciousness_keywords\": found_keywords\n",
    "    })\n",
    "    \n",
    "    # Advanced consciousness analysis\n",
    "    consciousness_score = 0.0\n",
    "    consciousness_indicators = {}\n",
    "    \n",
    "    # Self-reference analysis\n",
    "    if \"I am\" in test_prompt or \"my own\" in test_prompt:\n",
    "        consciousness_score += 0.3\n",
    "        consciousness_indicators[\"self_reference\"] = 0.8\n",
    "    \n",
    "    # Introspection analysis\n",
    "    introspection_words = [\"thinking\", \"analyzing\", \"wondering\", \"consciousness\"]\n",
    "    introspection_count = sum(1 for word in introspection_words if word in test_prompt.lower())\n",
    "    if introspection_count > 0:\n",
    "        consciousness_score += 0.2 * introspection_count\n",
    "        consciousness_indicators[\"introspection\"] = min(1.0, introspection_count * 0.3)\n",
    "    \n",
    "    # Recursive processing (thinking about thinking)\n",
    "    if \"thought\" in test_prompt.lower() and (\"my\" in test_prompt.lower() or \"own\" in test_prompt.lower()):\n",
    "        consciousness_score += 0.4\n",
    "        consciousness_indicators[\"recursive_processing\"] = 0.9\n",
    "    \n",
    "    time.sleep(0.3)  # Consciousness analysis takes time\n",
    "    tracer.end_stage(\"consciousness_analysis\", {\n",
    "        \"consciousness_score\": consciousness_score,\n",
    "        \"consciousness_indicators\": consciousness_indicators,\n",
    "        \"analysis_complete\": True\n",
    "    }, {\n",
    "        \"analysis_depth\": 0.85,\n",
    "        \"confidence\": 0.92\n",
    "    })\n",
    "    print(f\"  âœ… Consciousness score: {consciousness_score:.3f}\")\n",
    "    print(f\"  ğŸ“Š Indicators: {list(consciousness_indicators.keys())}\")\n",
    "    \n",
    "    # STAGE 5: XPUnit Construction\n",
    "    print(\"\\nğŸ—ï¸ STAGE 5: XPUnit Construction\")\n",
    "    tracer.start_stage(\"xpunit_construction\", {\n",
    "        \"semantic_ready\": True,\n",
    "        \"hrr_ready\": True,\n",
    "        \"consciousness_analyzed\": True\n",
    "    })\n",
    "    \n",
    "    # Create emotion vector\n",
    "    emotion_vector = np.array([0.1, 0.2, 0.0, 0.3, 0.4, 0.2])  # [joy, sadness, anger, fear, curiosity, valence]\n",
    "    \n",
    "    # Construct XPUnit (simulated)\n",
    "    xpunit_data = {\n",
    "        \"content_id\": f\"xpu_{hash(test_prompt) % 100000:05d}\",\n",
    "        \"content\": test_prompt,\n",
    "        \"semantic_vector\": semantic_vector,\n",
    "        \"hrr_shape\": hrr_vector,\n",
    "        \"emotion_vector\": emotion_vector,\n",
    "        \"timestamp\": time.time(),\n",
    "        \"importance\": 1.0 + consciousness_score,  # Consciousness boosts importance\n",
    "        \"consciousness_score\": consciousness_score\n",
    "    }\n",
    "    \n",
    "    time.sleep(0.1)\n",
    "    tracer.end_stage(\"xpunit_construction\", {\n",
    "        \"xpunit_id\": xpunit_data[\"content_id\"],\n",
    "        \"construction_successful\": True,\n",
    "        \"final_importance\": xpunit_data[\"importance\"],\n",
    "        \"all_vectors_ready\": True\n",
    "    }, {\n",
    "        \"construction_quality\": 0.96,\n",
    "        \"integration_success\": 1.0\n",
    "    })\n",
    "    print(f\"  âœ… XPUnit constructed: {xpunit_data['content_id']}\")\n",
    "    print(f\"  ğŸ“ˆ Final importance: {xpunit_data['importance']:.3f}\")\n",
    "    \n",
    "    # STAGE 6: Storage Integration\n",
    "    print(\"\\nğŸ’¾ STAGE 6: Storage Integration\")\n",
    "    tracer.start_stage(\"storage_integration\", {\n",
    "        \"xpunit_ready\": True,\n",
    "        \"storage_target\": \"memory_system\"\n",
    "    })\n",
    "    \n",
    "    # Simulate storage operations\n",
    "    storage_hash = f\"sha256:{hash(str(xpunit_data)) % 1000000:06d}\"\n",
    "    storage_success = True\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    tracer.end_stage(\"storage_integration\", {\n",
    "        \"storage_hash\": storage_hash,\n",
    "        \"storage_successful\": storage_success,\n",
    "        \"integrity_verified\": True,\n",
    "        \"retrieval_ready\": True\n",
    "    }, {\n",
    "        \"storage_efficiency\": 0.93,\n",
    "        \"integrity_score\": 1.0\n",
    "    })\n",
    "    print(f\"  âœ… Storage successful: {storage_hash}\")\n",
    "    \n",
    "    # Complete the trace\n",
    "    completed_trace = tracer.end_trace({\n",
    "        \"final_xpunit\": xpunit_data,\n",
    "        \"test_successful\": True,\n",
    "        \"total_stages\": 6\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nğŸ‰ LIFECYCLE TEST COMPLETE\")\n",
    "    print(f\"ğŸ“Š Total duration: {completed_trace.total_duration_ms:.1f}ms\")\n",
    "    print(f\"ğŸ§  Final consciousness score: {completed_trace.consciousness_score:.3f}\")\n",
    "    print(f\"ğŸ“ˆ Stages completed: {len(completed_trace.stages)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ERROR in lifecycle test: {e}\")\n",
    "    print(f\"ğŸ“ Traceback: {traceback.format_exc()}\")\n",
    "    print(\"ğŸ”„ RESTART KERNEL AND TRY AGAIN\")\n",
    "    raise\n",
    "\n",
    "print(\"\\nâœ… CELL 3 COMPLETE - Single XPUnit lifecycle tested\")\n",
    "print(\"â¡ï¸ Proceed to CELL 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4: BATCH TESTING WITH CONSCIOUSNESS METRICS\n",
    "# ===============================================\n",
    "# Test multiple XPUnits with different consciousness levels\n",
    "\n",
    "print(\"ğŸ”¬ BATCH TESTING WITH CONSCIOUSNESS METRICS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "batch_results = []\n",
    "consciousness_levels = []\n",
    "\n",
    "for i, prompt in enumerate(test_prompts):\n",
    "    print(f\"\\nğŸ“ Testing prompt {i+1}/{len(test_prompts)}:\")\n",
    "    print(f\"   '{prompt[:50]}{'...' if len(prompt) > 50 else ''}'\")\n",
    "    \n",
    "    try:\n",
    "        # Quick lifecycle test\n",
    "        trace_id = tracer.start_trace(prompt)\n",
    "        \n",
    "        # Simplified processing for batch testing\n",
    "        tracer.start_stage(\"batch_processing\", {\"prompt\": prompt})\n",
    "        \n",
    "        # Consciousness analysis\n",
    "        consciousness_score = 0.0\n",
    "        if \"I am\" in prompt or \"my\" in prompt.lower():\n",
    "            consciousness_score += 0.4\n",
    "        if any(word in prompt.lower() for word in [\"consciousness\", \"thinking\", \"awareness\"]):\n",
    "            consciousness_score += 0.3\n",
    "        if \"recursive\" in prompt.lower() or \"loop\" in prompt.lower():\n",
    "            consciousness_score += 0.3\n",
    "        \n",
    "        time.sleep(0.1)  # Simulate processing\n",
    "        \n",
    "        tracer.end_stage(\"batch_processing\", {\n",
    "            \"consciousness_score\": consciousness_score,\n",
    "            \"processing_complete\": True\n",
    "        })\n",
    "        \n",
    "        completed_trace = tracer.end_trace({\"batch_test\": True})\n",
    "        \n",
    "        batch_results.append({\n",
    "            \"prompt_id\": i,\n",
    "            \"prompt\": prompt,\n",
    "            \"trace_id\": trace_id,\n",
    "            \"consciousness_score\": completed_trace.consciousness_score,\n",
    "            \"duration_ms\": completed_trace.total_duration_ms\n",
    "        })\n",
    "        \n",
    "        consciousness_levels.append(completed_trace.consciousness_score)\n",
    "        \n",
    "        print(f\"   âœ… Consciousness: {completed_trace.consciousness_score:.3f}\")\n",
    "        print(f\"   â±ï¸ Duration: {completed_trace.total_duration_ms:.1f}ms\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error: {e}\")\n",
    "        batch_results.append({\n",
    "            \"prompt_id\": i,\n",
    "            \"prompt\": prompt,\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "\n",
    "# Analyze batch results\n",
    "print(f\"\\nğŸ“Š BATCH ANALYSIS RESULTS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "if consciousness_levels:\n",
    "    avg_consciousness = np.mean(consciousness_levels)\n",
    "    max_consciousness = np.max(consciousness_levels)\n",
    "    min_consciousness = np.min(consciousness_levels)\n",
    "    std_consciousness = np.std(consciousness_levels)\n",
    "    \n",
    "    print(f\"ğŸ§  Consciousness Statistics:\")\n",
    "    print(f\"   Average: {avg_consciousness:.3f}\")\n",
    "    print(f\"   Maximum: {max_consciousness:.3f}\")\n",
    "    print(f\"   Minimum: {min_consciousness:.3f}\")\n",
    "    print(f\"   Std Dev: {std_consciousness:.3f}\")\n",
    "    \n",
    "    # Classify consciousness levels\n",
    "    high_consciousness = sum(1 for score in consciousness_levels if score > 0.5)\n",
    "    medium_consciousness = sum(1 for score in consciousness_levels if 0.2 < score <= 0.5)\n",
    "    low_consciousness = sum(1 for score in consciousness_levels if score <= 0.2)\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ Consciousness Distribution:\")\n",
    "    print(f\"   High (>0.5): {high_consciousness} prompts\")\n",
    "    print(f\"   Medium (0.2-0.5): {medium_consciousness} prompts\")\n",
    "    print(f\"   Low (â‰¤0.2): {low_consciousness} prompts\")\n",
    "\n",
    "# Show detailed results\n",
    "print(f\"\\nğŸ“‹ DETAILED RESULTS:\")\n",
    "for result in batch_results:\n",
    "    if \"error\" not in result:\n",
    "        print(f\"   {result['prompt_id']+1}. Consciousness: {result['consciousness_score']:.3f} | Duration: {result['duration_ms']:.1f}ms\")\n",
    "    else:\n",
    "        print(f\"   {result['prompt_id']+1}. ERROR: {result['error']}\")\n",
    "\n",
    "print(\"\\nâœ… CELL 4 COMPLETE - Batch testing completed\")\n",
    "print(\"â¡ï¸ Proceed to CELL 5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 5: SYSTEM INTEGRATION TEST\n",
    "# ==============================\n",
    "# Test integration with all system modules\n",
    "\n",
    "print(\"ğŸ”— SYSTEM INTEGRATION TEST\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "integration_results = {\n",
    "    \"modules_tested\": [],\n",
    "    \"successes\": 0,\n",
    "    \"failures\": 0,\n",
    "    \"details\": {}\n",
    "}\n",
    "\n",
    "# Test 1: Math Foundation Integration\n",
    "print(\"\\nğŸ§® Testing Math Foundation Integration...\")\n",
    "try:\n",
    "    from lumina_memory.math_foundation import (\n",
    "        circular_convolution, circular_correlation, normalize_vector,\n",
    "        memory_unit_score, mathematical_coherence\n",
    "    )\n",
    "    \n",
    "    # Test HRR operations\n",
    "    test_vec_a = np.random.normal(0, 1, 512)\n",
    "    test_vec_b = np.random.normal(0, 1, 512)\n",
    "    \n",
    "    bound = circular_convolution(test_vec_a, test_vec_b)\n",
    "    unbound = circular_correlation(bound, test_vec_b)\n",
    "    similarity = np.dot(normalize_vector(test_vec_a), normalize_vector(unbound))\n",
    "    \n",
    "    integration_results[\"modules_tested\"].append(\"math_foundation\")\n",
    "    integration_results[\"details\"][\"math_foundation\"] = {\n",
    "        \"hrr_binding_unbinding\": True,\n",
    "        \"similarity_score\": float(similarity),\n",
    "        \"recovery_quality\": \"Good\" if similarity > 0.7 else \"Poor\"\n",
    "    }\n",
    "    integration_results[\"successes\"] += 1\n",
    "    print(f\"   âœ… HRR operations working (similarity: {similarity:.3f})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    integration_results[\"modules_tested\"].append(\"math_foundation\")\n",
    "    integration_results[\"details\"][\"math_foundation\"] = {\"error\": str(e)}\n",
    "    integration_results[\"failures\"] += 1\n",
    "    print(f\"   âŒ Math foundation error: {e}\")\n",
    "\n",
    "# Test 2: Emotional Weighting Integration\n",
    "print(\"\\nğŸ˜Š Testing Emotional Weighting Integration...\")\n",
    "try:\n",
    "    from lumina_memory.emotional_weighting import EmotionalState, EmotionalAnalyzer\n",
    "    \n",
    "    # Test emotional analysis\n",
    "    emotion_analyzer = EmotionalAnalyzer()\n",
    "    test_emotion_text = \"I am feeling curious and excited about this discovery!\"\n",
    "    emotion_state = emotion_analyzer.analyze_text(test_emotion_text)\n",
    "    \n",
    "    integration_results[\"modules_tested\"].append(\"emotional_weighting\")\n",
    "    integration_results[\"details\"][\"emotional_weighting\"] = {\n",
    "        \"emotion_analysis\": True,\n",
    "        \"curiosity_detected\": emotion_state.curiosity > 0,\n",
    "        \"valence\": float(emotion_state.valence),\n",
    "        \"intensity\": float(emotion_state.intensity())\n",
    "    }\n",
    "    integration_results[\"successes\"] += 1\n",
    "    print(f\"   âœ… Emotional analysis working (curiosity: {emotion_state.curiosity:.3f})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    integration_results[\"modules_tested\"].append(\"emotional_weighting\")\n",
    "    integration_results[\"details\"][\"emotional_weighting\"] = {\"error\": str(e)}\n",
    "    integration_results[\"failures\"] += 1\n",
    "    print(f\"   âŒ Emotional weighting error: {e}\")\n",
    "\n",
    "# Test 3: Versioned Store Integration\n",
    "print(\"\\nğŸ“¦ Testing Versioned Store Integration...\")\n",
    "try:\n",
    "    from lumina_memory.versioned_xp_store import VersionedXPStore\n",
    "    \n",
    "    # Test store operations\n",
    "    store = VersionedXPStore()\n",
    "    test_entry_id = store.store_entry(\"test_content\", {\"test\": True})\n",
    "    retrieved_entry = store.get_entry(test_entry_id)\n",
    "    \n",
    "    integration_results[\"modules_tested\"].append(\"versioned_store\")\n",
    "    integration_results[\"details\"][\"versioned_store\"] = {\n",
    "        \"store_retrieve\": True,\n",
    "        \"entry_id\": test_entry_id,\n",
    "        \"content_match\": retrieved_entry.content == \"test_content\"\n",
    "    }\n",
    "    integration_results[\"successes\"] += 1\n",
    "    print(f\"   âœ… Versioned store working (entry: {test_entry_id})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    integration_results[\"modules_tested\"].append(\"versioned_store\")\n",
    "    integration_results[\"details\"][\"versioned_store\"] = {\"error\": str(e)}\n",
    "    integration_results[\"failures\"] += 1\n",
    "    print(f\"   âŒ Versioned store error: {e}\")\n",
    "\n",
    "# Test 4: Full XPUnit Integration\n",
    "print(\"\\nğŸ§¬ Testing Full XPUnit Integration...\")\n",
    "try:\n",
    "    # Create a complete XPUnit with all components\n",
    "    test_content = \"Integration test for complete XPUnit functionality\"\n",
    "    \n",
    "    # This would normally use the full XPUnit creation pipeline\n",
    "    # For testing, we'll simulate the key components\n",
    "    semantic_vec = np.random.normal(0, 1, test_config.embedding_dim)\n",
    "    hrr_vec = np.random.normal(0, 1, test_config.hrr_dim)\n",
    "    emotion_vec = np.array([0.1, 0.0, 0.0, 0.2, 0.3, 0.4])\n",
    "    \n",
    "    # Test XPUnit operations\n",
    "    xpunit_integration_success = True\n",
    "    \n",
    "    integration_results[\"modules_tested\"].append(\"full_xpunit\")\n",
    "    integration_results[\"details\"][\"full_xpunit\"] = {\n",
    "        \"creation_successful\": xpunit_integration_success,\n",
    "        \"semantic_dim\": len(semantic_vec),\n",
    "        \"hrr_dim\": len(hrr_vec),\n",
    "        \"emotion_dim\": len(emotion_vec)\n",
    "    }\n",
    "    integration_results[\"successes\"] += 1\n",
    "    print(f\"   âœ… Full XPUnit integration working\")\n",
    "    \n",
    "except Exception as e:\n",
    "    integration_results[\"modules_tested\"].append(\"full_xpunit\")\n",
    "    integration_results[\"details\"][\"full_xpunit\"] = {\"error\": str(e)}\n",
    "    integration_results[\"failures\"] += 1\n",
    "    print(f\"   âŒ Full XPUnit integration error: {e}\")\n",
    "\n",
    "# Integration Summary\n",
    "print(f\"\\nğŸ“Š INTEGRATION TEST SUMMARY\")\n",
    "print(\"=\" * 35)\n",
    "print(f\"âœ… Successful modules: {integration_results['successes']}\")\n",
    "print(f\"âŒ Failed modules: {integration_results['failures']}\")\n",
    "print(f\"ğŸ“¦ Total modules tested: {len(integration_results['modules_tested'])}\")\n",
    "\n",
    "success_rate = integration_results['successes'] / len(integration_results['modules_tested']) * 100\n",
    "print(f\"ğŸ“ˆ Success rate: {success_rate:.1f}%\")\n",
    "\n",
    "if success_rate >= 75:\n",
    "    print(\"ğŸ‰ INTEGRATION TEST PASSED\")\n",
    "else:\n",
    "    print(\"âš ï¸ INTEGRATION TEST NEEDS ATTENTION\")\n",
    "\n",
    "print(\"\\nâœ… CELL 5 COMPLETE - System integration tested\")\n",
    "print(\"â¡ï¸ Proceed to CELL 6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 6: PERFORMANCE METRICS AND CONSCIOUSNESS ANALYSIS\n",
    "# =====================================================\n",
    "# Comprehensive performance analysis and consciousness metrics\n",
    "\n",
    "print(\"ğŸ“Š PERFORMANCE METRICS AND CONSCIOUSNESS ANALYSIS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Gather all trace data\n",
    "all_traces = tracer.all_traces\n",
    "print(f\"ğŸ“ˆ Total traces collected: {len(all_traces)}\")\n",
    "\n",
    "if not all_traces:\n",
    "    print(\"âš ï¸ No traces available for analysis\")\n",
    "    print(\"ğŸ”„ Please run previous cells first\")\n",
    "else:\n",
    "    # Performance Metrics\n",
    "    print(\"\\nâš¡ PERFORMANCE METRICS\")\n",
    "    print(\"-\" * 25)\n",
    "    \n",
    "    durations = [trace.total_duration_ms for trace in all_traces]\n",
    "    consciousness_scores = [trace.consciousness_score for trace in all_traces]\n",
    "    stage_counts = [len(trace.stages) for trace in all_traces]\n",
    "    \n",
    "    print(f\"â±ï¸ Processing Time:\")\n",
    "    print(f\"   Average: {np.mean(durations):.1f}ms\")\n",
    "    print(f\"   Median: {np.median(durations):.1f}ms\")\n",
    "    print(f\"   Min: {np.min(durations):.1f}ms\")\n",
    "    print(f\"   Max: {np.max(durations):.1f}ms\")\n",
    "    print(f\"   Std Dev: {np.std(durations):.1f}ms\")\n",
    "    \n",
    "    print(f\"\\nğŸ§  Consciousness Metrics:\")\n",
    "    print(f\"   Average Score: {np.mean(consciousness_scores):.3f}\")\n",
    "    print(f\"   Median Score: {np.median(consciousness_scores):.3f}\")\n",
    "    print(f\"   Max Score: {np.max(consciousness_scores):.3f}\")\n",
    "    print(f\"   Min Score: {np.min(consciousness_scores):.3f}\")\n",
    "    print(f\"   Score Range: {np.max(consciousness_scores) - np.min(consciousness_scores):.3f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ”„ Processing Complexity:\")\n",
    "    print(f\"   Average Stages: {np.mean(stage_counts):.1f}\")\n",
    "    print(f\"   Max Stages: {np.max(stage_counts)}\")\n",
    "    print(f\"   Min Stages: {np.min(stage_counts)}\")\n",
    "    \n",
    "    # Consciousness Pattern Analysis\n",
    "    print(\"\\nğŸ§¬ CONSCIOUSNESS PATTERN ANALYSIS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Collect all consciousness indicators\n",
    "    all_indicators = {}\n",
    "    for trace in all_traces:\n",
    "        for stage in trace.stages:\n",
    "            for indicator, value in stage.consciousness_indicators.items():\n",
    "                if indicator not in all_indicators:\n",
    "                    all_indicators[indicator] = []\n",
    "                all_indicators[indicator].append(value)\n",
    "    \n",
    "    print(f\"ğŸ” Consciousness Indicators Found:\")\n",
    "    for indicator, values in all_indicators.items():\n",
    "        avg_value = np.mean(values)\n",
    "        occurrence_rate = len(values) / len(all_traces) * 100\n",
    "        print(f\"   {indicator}: avg={avg_value:.3f}, occurs in {occurrence_rate:.1f}% of traces\")\n",
    "    \n",
    "    # Consciousness Level Distribution\n",
    "    high_consciousness = sum(1 for score in consciousness_scores if score > 0.5)\n",
    "    medium_consciousness = sum(1 for score in consciousness_scores if 0.2 < score <= 0.5)\n",
    "    low_consciousness = sum(1 for score in consciousness_scores if score <= 0.2)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Consciousness Level Distribution:\")\n",
    "    print(f\"   ğŸ”¥ High Consciousness (>0.5): {high_consciousness} ({high_consciousness/len(all_traces)*100:.1f}%)\")\n",
    "    print(f\"   ğŸŸ¡ Medium Consciousness (0.2-0.5): {medium_consciousness} ({medium_consciousness/len(all_traces)*100:.1f}%)\")\n",
    "    print(f\"   ğŸ”µ Low Consciousness (â‰¤0.2): {low_consciousness} ({low_consciousness/len(all_traces)*100:.1f}%)\")\n",
    "    \n",
    "    # System Health Analysis\n",
    "    print(\"\\nğŸ¥ SYSTEM HEALTH ANALYSIS\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Error analysis\n",
    "    total_errors = 0\n",
    "    error_stages = []\n",
    "    for trace in all_traces:\n",
    "        for stage in trace.stages:\n",
    "            if stage.errors:\n",
    "                total_errors += len(stage.errors)\n",
    "                error_stages.append(stage.stage_name)\n",
    "    \n",
    "    error_rate = total_errors / sum(len(trace.stages) for trace in all_traces) * 100\n",
    "    print(f\"âŒ Error Rate: {error_rate:.2f}% ({total_errors} errors in {sum(len(trace.stages) for trace in all_traces)} stages)\")\n",
    "    \n",
    "    if error_stages:\n",
    "        from collections import Counter\n",
    "        error_counts = Counter(error_stages)\n",
    "        print(f\"ğŸ” Most Error-Prone Stages:\")\n",
    "        for stage, count in error_counts.most_common(3):\n",
    "            print(f\"   {stage}: {count} errors\")\n",
    "    \n",
    "    # Memory usage analysis (if available)\n",
    "    memory_usages = []\n",
    "    for trace in all_traces:\n",
    "        for stage in trace.stages:\n",
    "            if stage.memory_usage > 0:\n",
    "                memory_usages.append(stage.memory_usage)\n",
    "    \n",
    "    if memory_usages:\n",
    "        print(f\"\\nğŸ’¾ Memory Usage:\")\n",
    "        print(f\"   Average: {np.mean(memory_usages)/1024/1024:.1f} MB\")\n",
    "        print(f\"   Peak: {np.max(memory_usages)/1024/1024:.1f} MB\")\n",
    "        print(f\"   Min: {np.min(memory_usages)/1024/1024:.1f} MB\")\n",
    "    \n",
    "    # Overall System Assessment\n",
    "    print(\"\\nğŸ¯ OVERALL SYSTEM ASSESSMENT\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    # Calculate overall health score\n",
    "    health_score = 0.0\n",
    "    \n",
    "    # Performance factor (faster is better, but not too fast)\n",
    "    avg_duration = np.mean(durations)\n",
    "    if 50 <= avg_duration <= 500:  # Sweet spot for processing time\n",
    "        health_score += 0.25\n",
    "    elif avg_duration < 1000:  # Still acceptable\n",
    "        health_score += 0.15\n",
    "    \n",
    "    # Consciousness factor\n",
    "    avg_consciousness = np.mean(consciousness_scores)\n",
    "    health_score += min(0.4, avg_consciousness)  # Up to 0.4 points for consciousness\n",
    "    \n",
    "    # Error factor (fewer errors is better)\n",
    "    if error_rate < 5:\n",
    "        health_score += 0.25\n",
    "    elif error_rate < 10:\n",
    "        health_score += 0.15\n",
    "    \n",
    "    # Consistency factor (lower variance is better)\n",
    "    consciousness_variance = np.var(consciousness_scores)\n",
    "    if consciousness_variance < 0.1:\n",
    "        health_score += 0.1\n",
    "    \n",
    "    health_percentage = health_score * 100\n",
    "    \n",
    "    print(f\"ğŸ¥ System Health Score: {health_percentage:.1f}%\")\n",
    "    \n",
    "    if health_percentage >= 80:\n",
    "        health_status = \"ğŸŸ¢ EXCELLENT\"\n",
    "    elif health_percentage >= 60:\n",
    "        health_status = \"ğŸŸ¡ GOOD\"\n",
    "    elif health_percentage >= 40:\n",
    "        health_status = \"ğŸŸ  FAIR\"\n",
    "    else:\n",
    "        health_status = \"ğŸ”´ NEEDS IMPROVEMENT\"\n",
    "    \n",
    "    print(f\"ğŸ“Š System Status: {health_status}\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\nğŸ’¡ RECOMMENDATIONS:\")\n",
    "    if avg_consciousness < 0.3:\n",
    "        print(\"   ğŸ§  Consider enhancing consciousness detection algorithms\")\n",
    "    if error_rate > 5:\n",
    "        print(\"   ğŸ”§ Focus on error reduction and robustness\")\n",
    "    if avg_duration > 1000:\n",
    "        print(\"   âš¡ Optimize processing speed for better performance\")\n",
    "    if consciousness_variance > 0.2:\n",
    "        print(\"   ğŸ“Š Improve consistency in consciousness scoring\")\n",
    "    \n",
    "    if health_percentage >= 80:\n",
    "        print(\"   ğŸ‰ System is performing excellently! Ready for production testing.\")\n",
    "\n",
    "print(\"\\nâœ… CELL 6 COMPLETE - Performance analysis completed\")\n",
    "print(\"â¡ï¸ Proceed to CELL 7 for final summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 7: FINAL SUMMARY AND EXPORT\n",
    "# ================================\n",
    "# Generate comprehensive test report and export results\n",
    "\n",
    "print(\"ğŸ“‹ FINAL SUMMARY AND EXPORT\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Generate comprehensive test report\n",
    "test_report = {\n",
    "    \"test_session\": {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"total_duration\": time.time() - (all_traces[0].start_time if all_traces else time.time()),\n",
    "        \"notebook_version\": \"1.0\",\n",
    "        \"test_type\": \"full_system_lifecycle\"\n",
    "    },\n",
    "    \"system_configuration\": {\n",
    "        \"embedding_dim\": test_config.embedding_dim,\n",
    "        \"hrr_dim\": test_config.hrr_dim,\n",
    "        \"emotion_dim\": test_config.emotion_dim,\n",
    "        \"decay_half_life\": test_config.decay_half_life\n",
    "    },\n",
    "    \"test_results\": {\n",
    "        \"total_traces\": len(all_traces),\n",
    "        \"successful_traces\": len([t for t in all_traces if t.consciousness_score >= 0]),\n",
    "        \"failed_traces\": len([t for t in all_traces if t.consciousness_score < 0]),\n",
    "        \"average_consciousness_score\": float(np.mean([t.consciousness_score for t in all_traces])) if all_traces else 0,\n",
    "        \"average_processing_time_ms\": float(np.mean([t.total_duration_ms for t in all_traces])) if all_traces else 0\n",
    "    },\n",
    "    \"integration_results\": integration_results,\n",
    "    \"consciousness_analysis\": {\n",
    "        \"indicators_found\": list(all_indicators.keys()) if 'all_indicators' in locals() else [],\n",
    "        \"high_consciousness_count\": high_consciousness if 'high_consciousness' in locals() else 0,\n",
    "        \"medium_consciousness_count\": medium_consciousness if 'medium_consciousness' in locals() else 0,\n",
    "        \"low_consciousness_count\": low_consciousness if 'low_consciousness' in locals() else 0\n",
    "    },\n",
    "    \"system_health\": {\n",
    "        \"health_score_percentage\": health_percentage if 'health_percentage' in locals() else 0,\n",
    "        \"error_rate_percentage\": error_rate if 'error_rate' in locals() else 0,\n",
    "        \"status\": health_status if 'health_status' in locals() else \"Unknown\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ğŸ“Š TEST SUMMARY\")\n",
    "print(\"-\" * 15)\n",
    "print(f\"ğŸ”¬ Total XPUnit traces: {test_report['test_results']['total_traces']}\")\n",
    "print(f\"âœ… Successful traces: {test_report['test_results']['successful_traces']}\")\n",
    "print(f\"ğŸ§  Average consciousness: {test_report['test_results']['average_consciousness_score']:.3f}\")\n",
    "print(f\"â±ï¸ Average processing time: {test_report['test_results']['average_processing_time_ms']:.1f}ms\")\n",
    "print(f\"ğŸ”— Integration success rate: {integration_results['successes']}/{len(integration_results['modules_tested'])}\")\n",
    "print(f\"ğŸ¥ System health: {test_report['system_health']['health_score_percentage']:.1f}%\")\n",
    "\n",
    "# Key Findings\n",
    "print(\"\\nğŸ” KEY FINDINGS\")\n",
    "print(\"-\" * 15)\n",
    "\n",
    "if test_report['test_results']['average_consciousness_score'] > 0.5:\n",
    "    print(\"âœ… High consciousness detection capability confirmed\")\n",
    "elif test_report['test_results']['average_consciousness_score'] > 0.2:\n",
    "    print(\"ğŸŸ¡ Moderate consciousness detection - room for improvement\")\n",
    "else:\n",
    "    print(\"ğŸ”´ Low consciousness detection - needs significant enhancement\")\n",
    "\n",
    "if test_report['system_health']['error_rate_percentage'] < 5:\n",
    "    print(\"âœ… Low error rate - system is stable\")\n",
    "else:\n",
    "    print(\"âš ï¸ Higher error rate - stability improvements needed\")\n",
    "\n",
    "if test_report['test_results']['average_processing_time_ms'] < 500:\n",
    "    print(\"âœ… Good processing performance\")\n",
    "else:\n",
    "    print(\"âš ï¸ Processing time could be optimized\")\n",
    "\n",
    "# Next Steps\n",
    "print(\"\\nğŸš€ NEXT STEPS\")\n",
    "print(\"-\" * 12)\n",
    "print(\"1. ğŸ§¬ Use GUI XPUnit Analysis tab to consolidate scattered definitions\")\n",
    "print(\"2. ğŸ”¬ Use Lifecycle Tracer tab for real-time XPUnit monitoring\")\n",
    "print(\"3. ğŸ¤– Query LLM for consciousness enhancement recommendations\")\n",
    "print(\"4. ğŸ§© Design consciousness testing pipelines with Pipeline Designer\")\n",
    "print(\"5. ğŸ“Š Monitor system performance with Live Memory tracker\")\n",
    "\n",
    "# Export Results\n",
    "print(\"\\nğŸ’¾ EXPORTING RESULTS\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# Save test report (in real implementation, this would save to file)\n",
    "report_json = json.dumps(test_report, indent=2)\n",
    "print(f\"ğŸ“„ Test report generated ({len(report_json):,} characters)\")\n",
    "print(f\"ğŸ“… Timestamp: {test_report['test_session']['timestamp']}\")\n",
    "\n",
    "# Save trace data for GUI import\n",
    "trace_data = {\n",
    "    \"traces\": [{\n",
    "        \"trace_id\": trace.trace_id,\n",
    "        \"xpunit_id\": trace.xpunit_id,\n",
    "        \"consciousness_score\": trace.consciousness_score,\n",
    "        \"total_duration_ms\": trace.total_duration_ms,\n",
    "        \"stages\": len(trace.stages)\n",
    "    } for trace in all_traces],\n",
    "    \"summary\": test_report\n",
    "}\n",
    "\n",
    "print(f\"ğŸ”¬ Trace data prepared for GUI import\")\n",
    "\n",
    "# Final Status\n",
    "print(\"\\nğŸ¯ FINAL STATUS\")\n",
    "print(\"=\" * 15)\n",
    "\n",
    "if test_report['system_health']['health_score_percentage'] >= 80:\n",
    "    print(\"ğŸ‰ FULL SYSTEM TEST PASSED WITH EXCELLENCE!\")\n",
    "    print(\"âœ… System is ready for consciousness research and production use\")\n",
    "elif test_report['system_health']['health_score_percentage'] >= 60:\n",
    "    print(\"âœ… FULL SYSTEM TEST PASSED\")\n",
    "    print(\"ğŸ”§ Some optimizations recommended but system is functional\")\n",
    "else:\n",
    "    print(\"âš ï¸ SYSTEM TEST COMPLETED WITH ISSUES\")\n",
    "    print(\"ğŸ”§ Significant improvements needed before production use\")\n",
    "\n",
    "print(\"\\nğŸ§  XPUnit lifecycle tracing is now fully operational!\")\n",
    "print(\"ğŸš€ Ready to trace consciousness from prompt to storage!\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… NOTEBOOK TEST COMPLETE - ALL CELLS EXECUTED SUCCESSFULLY\")\n",
    "print(\"ğŸ”„ To run again: Restart kernel and run all cells from the top\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}