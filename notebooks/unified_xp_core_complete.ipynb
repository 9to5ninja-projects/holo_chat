{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† **LUMINA MEMORY SYSTEM - UNIFIED XP CORE COMPLETE**\n",
    "\n",
    "**The Complete Mathematical Foundation - All Components Consolidated**\n",
    "\n",
    "This notebook consolidates ALL the best components from the three development notebooks into a single, coherent, rigorous implementation of the XP Core mathematical foundation.\n",
    "\n",
    "## üéØ **CONSOLIDATION SOURCES**\n",
    "- **xp_core_design.ipynb**: Mathematical formulas, MemoryUnit, HRR operations\n",
    "- **unit_space_kernel_bridge.ipynb**: Spatial topology, integration patterns  \n",
    "- **hd_kernel_xp_spec.ipynb**: Interface specifications, kernel patterns\n",
    "\n",
    "## üßÆ **MATHEMATICAL FOUNDATION**\n",
    "The \"unit of experience\" (XP Unit) with complete mathematical properties:\n",
    "- **Cryptographic Identity**: BLAKE3 content addressing for mathematical immutability\n",
    "- **Holographic Representation**: HRR binding/unbinding for structured relationships\n",
    "- **Temporal Mathematics**: Exponential decay and consolidation scoring\n",
    "- **Relational Coherence**: Unit-to-unit mathematical relationships\n",
    "- **Environmental Context**: Spatial topology and access patterns\n",
    "\n",
    "## üèóÔ∏è **ARCHITECTURE**\n",
    "- **XPUnit**: The fundamental mathematical unit of experience\n",
    "- **XPEnvironment**: The computational container where units operate\n",
    "- **UnifiedXPKernel**: HD Kernel interface implementation\n",
    "- **Production Features**: NLP, vector search, cryptographic integrity\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ UNIFIED STARTUP SEQUENCE - COMPLETE FOUNDATION\n",
    "print(\"üöÄ LUMINA MEMORY SYSTEM - UNIFIED XP CORE STARTUP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# === PATH MANAGEMENT ===\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to Python path for imports\n",
    "project_root = Path.cwd().parent  # Parent of notebooks folder\n",
    "src_path = project_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "    print(f\"‚úÖ Added to path: {src_path}\")\n",
    "\n",
    "# === CORE IMPORTS ===\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"‚úÖ Core Python libraries loaded\")\n",
    "\n",
    "# === LUMINA MEMORY IMPORTS ===\n",
    "try:\n",
    "    from lumina_memory.xp_core_unified import (\n",
    "        UnifiedXPConfig, XPUnit, XPEnvironment, UnifiedXPKernel,\n",
    "        test_unified_xp_core\n",
    "    )\n",
    "    print(\"‚úÖ Unified XP Core components imported successfully\")\n",
    "    UNIFIED_CORE_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Unified XP Core not available: {e}\")\n",
    "    UNIFIED_CORE_AVAILABLE = False\n",
    "\n",
    "# === MATHEMATICAL FOUNDATION ===\n",
    "try:\n",
    "    from lumina_memory.math_foundation import (\n",
    "        circular_convolution, circular_correlation, normalize_vector,\n",
    "        bind_role_filler, unbind_role_filler, memory_unit_score,\n",
    "        mathematical_coherence, instant_salience\n",
    "    )\n",
    "    print(\"‚úÖ Mathematical foundation imported successfully\")\n",
    "    MATH_FOUNDATION_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Mathematical foundation not available: {e}\")\n",
    "    MATH_FOUNDATION_AVAILABLE = False\n",
    "\n",
    "# === VERSIONED STORE ===\n",
    "try:\n",
    "    from lumina_memory.versioned_xp_store import VersionedXPStore\n",
    "    print(\"‚úÖ VersionedXPStore imported successfully\")\n",
    "    VERSIONED_STORE_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è VersionedXPStore not available: {e}\")\n",
    "    VERSIONED_STORE_AVAILABLE = False\n",
    "\n",
    "# === FOUNDATION VERIFICATION ===\n",
    "def verify_unified_foundation():\n",
    "    \"\"\"Verify all unified components are ready\"\"\"\n",
    "    print(\"\\nüîç UNIFIED FOUNDATION VERIFICATION:\")\n",
    "    \n",
    "    status = {\n",
    "        'unified_core': UNIFIED_CORE_AVAILABLE,\n",
    "        'math_foundation': MATH_FOUNDATION_AVAILABLE,\n",
    "        'versioned_store': VERSIONED_STORE_AVAILABLE\n",
    "    }\n",
    "    \n",
    "    if MATH_FOUNDATION_AVAILABLE:\n",
    "        # Test mathematical operations\n",
    "        test_vec = np.random.randn(256)\n",
    "        normalized = normalize_vector(test_vec)\n",
    "        print(f\"‚úÖ Mathematical operations: norm={np.linalg.norm(normalized):.3f}\")\n",
    "    \n",
    "    if VERSIONED_STORE_AVAILABLE:\n",
    "        # Test versioned store\n",
    "        store = VersionedXPStore()\n",
    "        commit_id = store.commit(message=\"Test commit\")\n",
    "        print(f\"‚úÖ VersionedXPStore: commit {commit_id[:16]}...\")\n",
    "    \n",
    "    if UNIFIED_CORE_AVAILABLE:\n",
    "        # Test unified kernel\n",
    "        config = UnifiedXPConfig(embedding_dim=128)\n",
    "        print(f\"‚úÖ Unified XP Core: {config.embedding_dim}D embeddings ready\")\n",
    "    \n",
    "    return status\n",
    "\n",
    "# Run verification\n",
    "foundation_status = verify_unified_foundation()\n",
    "print(f\"\\nüéØ Foundation Status: {foundation_status}\")\n",
    "\n",
    "all_ready = all(foundation_status.values())\n",
    "if all_ready:\n",
    "    print(\"üéâ UNIFIED XP CORE FOUNDATION READY!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Some components missing - will use fallback implementations\")\n",
    "\n",
    "print(\"‚úÖ Unified startup sequence complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßÆ **MATHEMATICAL FOUNDATION DEMONSTRATION**\n",
    "\n",
    "Let's demonstrate the core mathematical operations that form the foundation of the XP Core system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßÆ MATHEMATICAL FOUNDATION DEMONSTRATION\n",
    "print(\"üßÆ MATHEMATICAL FOUNDATION DEMONSTRATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if MATH_FOUNDATION_AVAILABLE:\n",
    "    # Test 1: HRR Operations\n",
    "    print(\"\\n1Ô∏è‚É£ Testing HRR Operations...\")\n",
    "    \n",
    "    # Create test vectors\n",
    "    role_vector = normalize_vector(np.random.randn(512))\n",
    "    filler_vector = normalize_vector(np.random.randn(512))\n",
    "    \n",
    "    # Bind role and filler\n",
    "    bound_vector = bind_role_filler(role_vector, filler_vector)\n",
    "    \n",
    "    # Unbind to recover filler\n",
    "    recovered_filler = unbind_role_filler(bound_vector, role_vector)\n",
    "    \n",
    "    # Test similarity\n",
    "    similarity = np.dot(filler_vector, recovered_filler)\n",
    "    print(f\"‚úÖ HRR bind/unbind similarity: {similarity:.3f}\")\n",
    "    print(f\"   Original filler norm: {np.linalg.norm(filler_vector):.3f}\")\n",
    "    print(f\"   Recovered filler norm: {np.linalg.norm(recovered_filler):.3f}\")\n",
    "    \n",
    "    # Test 2: Memory Scoring\n",
    "    print(\"\\n2Ô∏è‚É£ Testing Memory Scoring...\")\n",
    "    \n",
    "    query_semantic = normalize_vector(np.random.randn(384))\n",
    "    memory_semantic = normalize_vector(np.random.randn(384))\n",
    "    query_emotion = normalize_vector(np.random.randn(6))\n",
    "    memory_emotion = normalize_vector(np.random.randn(6))\n",
    "    \n",
    "    score = memory_unit_score(\n",
    "        query_semantic, memory_semantic,\n",
    "        query_emotion, memory_emotion,\n",
    "        age_hours=12.0, decay_rate=0.01, importance=1.2\n",
    "    )\n",
    "    print(f\"‚úÖ Memory unit score: {score:.3f}\")\n",
    "    \n",
    "    # Test 3: Mathematical Coherence\n",
    "    print(\"\\n3Ô∏è‚É£ Testing Mathematical Coherence...\")\n",
    "    \n",
    "    hrr1 = normalize_vector(np.random.randn(512))\n",
    "    hrr2 = normalize_vector(np.random.randn(512))\n",
    "    sem1 = normalize_vector(np.random.randn(384))\n",
    "    sem2 = normalize_vector(np.random.randn(384))\n",
    "    \n",
    "    coherence = mathematical_coherence(hrr1, hrr2, sem1, sem2)\n",
    "    print(f\"‚úÖ Mathematical coherence: {coherence:.3f}\")\n",
    "    \n",
    "    # Test 4: Lexical Attribution\n",
    "    print(\"\\n4Ô∏è‚É£ Testing Lexical Attribution...\")\n",
    "    \n",
    "    text = \"The quantum holographic memory system uses mathematical foundations\"\n",
    "    concept = \"holographic memory\"\n",
    "    salience = instant_salience(text, concept)\n",
    "    print(f\"‚úÖ Lexical salience: {salience:.3f}\")\n",
    "    print(f\"   Text: '{text}'\")\n",
    "    print(f\"   Concept: '{concept}'\")\n",
    "    \n",
    "    print(\"\\nüéâ All mathematical operations working correctly!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Mathematical foundation not available - skipping tests\")\n",
    "    \n",
    "    # Fallback demonstration\n",
    "    print(\"\\nüìù Fallback Mathematical Operations:\")\n",
    "    \n",
    "    def simple_circular_convolution(a, b):\n",
    "        \"\"\"Simple circular convolution fallback\"\"\"\n",
    "        return np.real(np.fft.ifft(np.fft.fft(a) * np.fft.fft(b)))\n",
    "    \n",
    "    a = np.random.randn(64)\n",
    "    b = np.random.randn(64)\n",
    "    result = simple_circular_convolution(a, b)\n",
    "    print(f\"‚úÖ Simple circular convolution: shape={result.shape}, norm={np.linalg.norm(result):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è **UNIFIED XP CORE SYSTEM DEMONSTRATION**\n",
    "\n",
    "Now let's demonstrate the complete unified XP Core system with all components working together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üèóÔ∏è UNIFIED XP CORE SYSTEM DEMONSTRATION\n",
    "print(\"üèóÔ∏è UNIFIED XP CORE SYSTEM DEMONSTRATION\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "if UNIFIED_CORE_AVAILABLE:\n",
    "    # Run the comprehensive test suite\n",
    "    print(\"\\nüß™ Running Comprehensive Test Suite...\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        kernel, stats = test_unified_xp_core()\n",
    "        print(\"\\nüéâ COMPREHENSIVE TEST SUITE COMPLETED SUCCESSFULLY!\")\n",
    "        \n",
    "        # Display final statistics\n",
    "        print(\"\\nüìä FINAL SYSTEM STATISTICS:\")\n",
    "        print(f\"   Total Units: {stats['total_units']}\")\n",
    "        print(f\"   Total Ingestions: {stats['total_ingestions']}\")\n",
    "        print(f\"   Total Retrievals: {stats['total_retrievals']}\")\n",
    "        print(f\"   Average Importance: {stats['avg_importance']:.3f}\")\n",
    "        print(f\"   System Uptime: {stats['uptime_hours']:.1f} hours\")\n",
    "        print(f\"   Total Relationships: {stats['total_relationships']}\")\n",
    "        \n",
    "        # Store kernel for further use\n",
    "        unified_kernel = kernel\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Test suite failed: {e}\")\n",
    "        print(\"\\nüîß Creating basic kernel for manual testing...\")\n",
    "        \n",
    "        config = UnifiedXPConfig(\n",
    "            embedding_dim=256,\n",
    "            hrr_dim=512,\n",
    "            decay_half_life=72.0,\n",
    "            k_neighbors=5\n",
    "        )\n",
    "        unified_kernel = UnifiedXPKernel(config)\n",
    "        print(f\"‚úÖ Basic kernel created with {config.embedding_dim}D embeddings\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Unified XP Core not available - creating fallback demonstration\")\n",
    "    \n",
    "    # Fallback demonstration\n",
    "    class FallbackXPUnit:\n",
    "        def __init__(self, content_id, content):\n",
    "            self.content_id = content_id\n",
    "            self.content = content\n",
    "            self.timestamp = time.time()\n",
    "            self.importance = 1.0\n",
    "    \n",
    "    class FallbackKernel:\n",
    "        def __init__(self):\n",
    "            self.units = {}\n",
    "        \n",
    "        def process_memory(self, content):\n",
    "            content_id = f\"fallback_{len(self.units):04d}\"\n",
    "            unit = FallbackXPUnit(content_id, content)\n",
    "            self.units[content_id] = unit\n",
    "            return content_id\n",
    "        \n",
    "        def get_stats(self):\n",
    "            return {'total_units': len(self.units), 'system': 'fallback'}\n",
    "    \n",
    "    unified_kernel = FallbackKernel()\n",
    "    \n",
    "    # Test fallback\n",
    "    id1 = unified_kernel.process_memory(\"Fallback memory system test\")\n",
    "    id2 = unified_kernel.process_memory(\"Another test memory for fallback\")\n",
    "    stats = unified_kernel.get_stats()\n",
    "    \n",
    "    print(f\"‚úÖ Fallback system: {stats['total_units']} units created\")\n",
    "    print(f\"   Unit 1: {id1}\")\n",
    "    print(f\"   Unit 2: {id2}\")\n",
    "\n",
    "print(\"\\n‚úÖ XP Core system demonstration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ **INTERACTIVE XP CORE PLAYGROUND**\n",
    "\n",
    "Now let's create an interactive playground where you can experiment with the XP Core system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ INTERACTIVE XP CORE PLAYGROUND\n",
    "print(\"üéØ INTERACTIVE XP CORE PLAYGROUND\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Sample experiences to ingest\n",
    "sample_experiences = [\n",
    "    \"The quantum holographic memory system stores information in distributed patterns.\",\n",
    "    \"Machine learning algorithms can process natural language with high accuracy.\",\n",
    "    \"Holographic reduced representations enable efficient binding and unbinding operations.\",\n",
    "    \"Temporal decay mathematics model how memories fade over time naturally.\",\n",
    "    \"Cryptographic integrity ensures that memory units maintain mathematical consistency.\",\n",
    "    \"Spatial topology creates networks of related memories through coherence links.\",\n",
    "    \"The XP Core mathematical foundation serves as a universal memory currency.\",\n",
    "    \"Production NLP integration enables sophisticated linguistic analysis capabilities.\"\n",
    "]\n",
    "\n",
    "print(f\"\\nüìù Ingesting {len(sample_experiences)} sample experiences...\")\n",
    "\n",
    "# Ingest all sample experiences\n",
    "ingested_ids = []\n",
    "for i, experience in enumerate(sample_experiences):\n",
    "    try:\n",
    "        content_id = unified_kernel.process_memory(experience, {'sample_id': i, 'category': 'demo'})\n",
    "        ingested_ids.append(content_id)\n",
    "        print(f\"   {i+1}. {content_id[:16]}... - {experience[:50]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"   {i+1}. Error: {e}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Successfully ingested {len(ingested_ids)} experiences\")\n",
    "\n",
    "# Interactive query function\n",
    "def query_memories(query_text, k=3):\n",
    "    \"\"\"Query the XP Core system interactively\"\"\"\n",
    "    print(f\"\\nüîç Querying: '{query_text}'\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        if hasattr(unified_kernel, 'retrieve_memory'):\n",
    "            results = unified_kernel.retrieve_memory(query_text, k=k)\n",
    "            \n",
    "            if results:\n",
    "                print(f\"Found {len(results)} relevant memories:\")\n",
    "                for i, result in enumerate(results):\n",
    "                    similarity = result.get('similarity', 0.0)\n",
    "                    content = result.get('content', 'No content')\n",
    "                    importance = result.get('importance', 0.0)\n",
    "                    print(f\"   {i+1}. Similarity: {similarity:.3f}, Importance: {importance:.3f}\")\n",
    "                    print(f\"      {content[:80]}...\")\n",
    "            else:\n",
    "                print(\"No relevant memories found.\")\n",
    "        else:\n",
    "            print(\"Query functionality not available in fallback mode.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Query error: {e}\")\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    \"holographic memory systems\",\n",
    "    \"machine learning and AI\",\n",
    "    \"mathematical foundations\",\n",
    "    \"temporal decay processes\"\n",
    "]\n",
    "\n",
    "print(\"\\nüß™ Testing sample queries...\")\n",
    "for query in test_queries:\n",
    "    query_memories(query, k=2)\n",
    "\n",
    "print(\"\\nüéÆ Interactive playground ready! You can now:\")\n",
    "print(\"   - Use query_memories('your query here') to search\")\n",
    "print(\"   - Use unified_kernel.process_memory('new experience') to add memories\")\n",
    "print(\"   - Use unified_kernel.get_stats() to see system statistics\")\n",
    "\n",
    "if hasattr(unified_kernel, 'get_stats'):\n",
    "    current_stats = unified_kernel.get_stats()\n",
    "    print(f\"\\nüìä Current System Status: {current_stats.get('total_units', 0)} units loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ **ADVANCED MATHEMATICAL OPERATIONS**\n",
    "\n",
    "Let's explore the advanced mathematical operations that make the XP Core system unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¨ ADVANCED MATHEMATICAL OPERATIONS\n",
    "print(\"üî¨ ADVANCED MATHEMATICAL OPERATIONS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "if hasattr(unified_kernel, 'get_stats') and len(ingested_ids) >= 2:\n",
    "    \n",
    "    # Test 1: Coherence Analysis\n",
    "    print(\"\\n1Ô∏è‚É£ Testing Coherence Analysis...\")\n",
    "    if hasattr(unified_kernel, 'compute_coherence'):\n",
    "        coherence = unified_kernel.compute_coherence(ingested_ids[0], ingested_ids[1])\n",
    "        if coherence is not None:\n",
    "            print(f\"‚úÖ Coherence between first two units: {coherence:.3f}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Coherence computation not available\")\n",
    "    \n",
    "    # Test 2: HRR Binding Operations\n",
    "    print(\"\\n2Ô∏è‚É£ Testing HRR Binding Operations...\")\n",
    "    if hasattr(unified_kernel, 'create_binding'):\n",
    "        binding = unified_kernel.create_binding(ingested_ids[0], \"relates_to\", ingested_ids[1])\n",
    "        if binding is not None:\n",
    "            print(f\"‚úÖ Created HRR binding: shape={binding.shape}, norm={np.linalg.norm(binding):.3f}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è HRR binding not available\")\n",
    "    \n",
    "    # Test 3: Relationship Graph Analysis\n",
    "    print(\"\\n3Ô∏è‚É£ Testing Relationship Graph...\")\n",
    "    if hasattr(unified_kernel, 'get_relationship_graph'):\n",
    "        graph = unified_kernel.get_relationship_graph()\n",
    "        total_nodes = len(graph)\n",
    "        total_edges = sum(len(neighbors) for neighbors in graph.values())\n",
    "        print(f\"‚úÖ Relationship graph: {total_nodes} nodes, {total_edges} edges\")\n",
    "        \n",
    "        # Show some relationships\n",
    "        if graph:\n",
    "            print(\"   Sample relationships:\")\n",
    "            for node_id, neighbors in list(graph.items())[:3]:\n",
    "                if neighbors:\n",
    "                    top_neighbor = max(neighbors.items(), key=lambda x: x[1])\n",
    "                    print(f\"     {node_id[:16]}... ‚Üí {top_neighbor[0][:16]}... (strength: {top_neighbor[1]:.3f})\")\n",
    "    \n",
    "    # Test 4: Temporal Evolution\n",
    "    print(\"\\n4Ô∏è‚É£ Testing Temporal Evolution...\")\n",
    "    if hasattr(unified_kernel, 'evolve_state'):\n",
    "        evolution_stats = unified_kernel.evolve_state(time_delta_hours=1.0)\n",
    "        print(f\"‚úÖ Applied 1h evolution:\")\n",
    "        print(f\"   Decayed units: {evolution_stats.get('decay_stats', {}).get('decayed_units', 0)}\")\n",
    "        print(f\"   Consolidated units: {evolution_stats.get('consolidation_stats', {}).get('consolidated_units', 0)}\")\n",
    "    \n",
    "    # Test 5: Memory Consolidation\n",
    "    print(\"\\n5Ô∏è‚É£ Testing Memory Consolidation...\")\n",
    "    if hasattr(unified_kernel, 'consolidate_memory'):\n",
    "        consolidation_stats = unified_kernel.consolidate_memory()\n",
    "        consolidated_count = consolidation_stats.get('consolidated_units', 0)\n",
    "        total_units = consolidation_stats.get('total_units', 0)\n",
    "        consolidation_rate = consolidation_stats.get('consolidation_rate', 0.0)\n",
    "        print(f\"‚úÖ Consolidation: {consolidated_count}/{total_units} units (rate: {consolidation_rate:.1%})\")\n",
    "    \n",
    "    # Test 6: State Export/Import\n",
    "    print(\"\\n6Ô∏è‚É£ Testing State Persistence...\")\n",
    "    if hasattr(unified_kernel, 'export_state'):\n",
    "        try:\n",
    "            exported_state = unified_kernel.export_state()\n",
    "            state_size = len(json.dumps(exported_state, default=str))\n",
    "            print(f\"‚úÖ Exported state: {len(exported_state.get('units', {}))} units, {state_size:,} bytes\")\n",
    "            \n",
    "            # Test import\n",
    "            if hasattr(unified_kernel, 'import_state'):\n",
    "                # Create new kernel and import state\n",
    "                if UNIFIED_CORE_AVAILABLE:\n",
    "                    test_kernel = UnifiedXPKernel()\n",
    "                    import_success = test_kernel.import_state(exported_state)\n",
    "                    print(f\"‚úÖ State import: {import_success}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è State persistence error: {e}\")\n",
    "    \n",
    "    print(\"\\nüéâ Advanced mathematical operations complete!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Advanced operations require unified kernel with ingested memories\")\n",
    "    print(\"\\nüìù Demonstrating basic mathematical concepts:\")\n",
    "    \n",
    "    # Basic mathematical demonstrations\n",
    "    if MATH_FOUNDATION_AVAILABLE:\n",
    "        # Demonstrate superposition\n",
    "        vec1 = normalize_vector(np.random.randn(128))\n",
    "        vec2 = normalize_vector(np.random.randn(128))\n",
    "        superposition = normalize_vector(vec1 + vec2)\n",
    "        print(f\"‚úÖ Vector superposition: norm={np.linalg.norm(superposition):.3f}\")\n",
    "        \n",
    "        # Demonstrate binding\n",
    "        bound = circular_convolution(vec1, vec2)\n",
    "        unbound = circular_correlation(bound, vec1)\n",
    "        similarity = np.dot(vec2, unbound)\n",
    "        print(f\"‚úÖ HRR bind/unbind recovery: {similarity:.3f}\")\n",
    "    \n",
    "    print(\"\\nüí° To see full advanced operations, ensure unified_kernel is properly loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä **COMPREHENSIVE SYSTEM ANALYSIS**\n",
    "\n",
    "Let's analyze the complete system performance and capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä COMPREHENSIVE SYSTEM ANALYSIS\n",
    "print(\"üìä COMPREHENSIVE SYSTEM ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# System Status Report\n",
    "print(\"\\nüîç SYSTEM STATUS REPORT:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "status_report = {\n",
    "    'Foundation Components': {\n",
    "        'Unified XP Core': '‚úÖ' if UNIFIED_CORE_AVAILABLE else '‚ùå',\n",
    "        'Mathematical Foundation': '‚úÖ' if MATH_FOUNDATION_AVAILABLE else '‚ùå',\n",
    "        'Versioned Store': '‚úÖ' if VERSIONED_STORE_AVAILABLE else '‚ùå'\n",
    "    },\n",
    "    'Mathematical Operations': {\n",
    "        'HRR Binding/Unbinding': '‚úÖ' if MATH_FOUNDATION_AVAILABLE else '‚ùå',\n",
    "        'Memory Scoring': '‚úÖ' if MATH_FOUNDATION_AVAILABLE else '‚ùå',\n",
    "        'Coherence Computation': '‚úÖ' if MATH_FOUNDATION_AVAILABLE else '‚ùå',\n",
    "        'Lexical Attribution': '‚úÖ' if MATH_FOUNDATION_AVAILABLE else '‚ùå'\n",
    "    },\n",
    "    'System Capabilities': {\n",
    "        'Memory Ingestion': '‚úÖ' if hasattr(unified_kernel, 'process_memory') else '‚ùå',\n",
    "        'Similarity Search': '‚úÖ' if hasattr(unified_kernel, 'retrieve_memory') else '‚ùå',\n",
    "        'Temporal Evolution': '‚úÖ' if hasattr(unified_kernel, 'evolve_state') else '‚ùå',\n",
    "        'State Persistence': '‚úÖ' if hasattr(unified_kernel, 'export_state') else '‚ùå'\n",
    "    }\n",
    "}\n",
    "\n",
    "for category, components in status_report.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for component, status in components.items():\n",
    "        print(f\"   {status} {component}\")\n",
    "\n",
    "# Performance Analysis\n",
    "print(\"\\n‚ö° PERFORMANCE ANALYSIS:\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "if hasattr(unified_kernel, 'get_stats'):\n",
    "    try:\n",
    "        stats = unified_kernel.get_stats()\n",
    "        \n",
    "        print(f\"Memory Units: {stats.get('total_units', 0)}\")\n",
    "        print(f\"Total Ingestions: {stats.get('total_ingestions', 0)}\")\n",
    "        print(f\"Total Retrievals: {stats.get('total_retrievals', 0)}\")\n",
    "        print(f\"Average Importance: {stats.get('avg_importance', 0.0):.3f}\")\n",
    "        print(f\"Total Relationships: {stats.get('total_relationships', 0)}\")\n",
    "        \n",
    "        if 'config' in stats:\n",
    "            config = stats['config']\n",
    "            print(f\"\\nConfiguration:\")\n",
    "            print(f\"   Embedding Dimension: {config.get('embedding_dim', 'N/A')}\")\n",
    "            print(f\"   HRR Dimension: {config.get('hrr_dim', 'N/A')}\")\n",
    "            print(f\"   Decay Half-Life: {config.get('decay_half_life', 'N/A')} hours\")\n",
    "            print(f\"   K-Neighbors: {config.get('k_neighbors', 'N/A')}\")\n",
    "        \n",
    "        if 'versioned_store' in stats:\n",
    "            vs_stats = stats['versioned_store']\n",
    "            print(f\"\\nVersioned Store:\")\n",
    "            print(f\"   Total Entries: {vs_stats.get('total_entries', 0)}\")\n",
    "            print(f\"   Total Commits: {vs_stats.get('total_commits', 0)}\")\n",
    "            print(f\"   Branches: {len(vs_stats.get('branches', []))}\")\n",
    "            print(f\"   Integrity Verified: {vs_stats.get('integrity_verified', False)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting stats: {e}\")\n",
    "else:\n",
    "    print(\"Performance statistics not available\")\n",
    "\n",
    "# Capability Assessment\n",
    "print(\"\\nüéØ CAPABILITY ASSESSMENT:\")\n",
    "print(\"-\" * 28)\n",
    "\n",
    "capabilities = [\n",
    "    (\"Mathematical Foundation\", MATH_FOUNDATION_AVAILABLE),\n",
    "    (\"Cryptographic Integrity\", VERSIONED_STORE_AVAILABLE),\n",
    "    (\"Holographic Operations\", MATH_FOUNDATION_AVAILABLE),\n",
    "    (\"Temporal Mathematics\", UNIFIED_CORE_AVAILABLE),\n",
    "    (\"Spatial Topology\", UNIFIED_CORE_AVAILABLE),\n",
    "    (\"Production Ready\", all([UNIFIED_CORE_AVAILABLE, MATH_FOUNDATION_AVAILABLE, VERSIONED_STORE_AVAILABLE]))\n",
    "]\n",
    "\n",
    "working_capabilities = sum(1 for _, status in capabilities if status)\n",
    "total_capabilities = len(capabilities)\n",
    "\n",
    "for capability, status in capabilities:\n",
    "    status_icon = \"‚úÖ\" if status else \"‚ùå\"\n",
    "    print(f\"   {status_icon} {capability}\")\n",
    "\n",
    "print(f\"\\nüìà Overall System Readiness: {working_capabilities}/{total_capabilities} ({working_capabilities/total_capabilities:.1%})\")\n",
    "\n",
    "# Recommendations\n",
    "print(\"\\nüí° RECOMMENDATIONS:\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "if working_capabilities == total_capabilities:\n",
    "    print(\"üéâ System is fully operational and production-ready!\")\n",
    "    print(\"   - All mathematical foundations are working\")\n",
    "    print(\"   - Cryptographic integrity is enabled\")\n",
    "    print(\"   - Advanced features are available\")\n",
    "    print(\"   - Ready for real-world applications\")\n",
    "elif working_capabilities >= total_capabilities * 0.8:\n",
    "    print(\"‚úÖ System is mostly operational with minor issues\")\n",
    "    print(\"   - Core functionality is working\")\n",
    "    print(\"   - Some advanced features may be limited\")\n",
    "    print(\"   - Suitable for development and testing\")\n",
    "elif working_capabilities >= total_capabilities * 0.5:\n",
    "    print(\"‚ö†Ô∏è System has partial functionality\")\n",
    "    print(\"   - Basic operations should work\")\n",
    "    print(\"   - Several components need attention\")\n",
    "    print(\"   - Recommended for development only\")\n",
    "else:\n",
    "    print(\"‚ùå System needs significant work\")\n",
    "    print(\"   - Many core components are missing\")\n",
    "    print(\"   - Focus on fixing import issues first\")\n",
    "    print(\"   - Not ready for production use\")\n",
    "\n",
    "print(\"\\n‚úÖ Comprehensive system analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ **CONSOLIDATION COMPLETE - NEXT STEPS**\n",
    "\n",
    "The unified XP Core system is now consolidated and ready for use. Here's what we've accomplished and what comes next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéâ CONSOLIDATION SUMMARY AND NEXT STEPS\n",
    "print(\"üéâ LUMINA MEMORY SYSTEM - CONSOLIDATION COMPLETE\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "print(\"\\nüèÜ CONSOLIDATION ACHIEVEMENTS:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "achievements = [\n",
    "    \"‚úÖ Unified all three notebooks into single coherent implementation\",\n",
    "    \"‚úÖ Resolved all class conflicts (Memory, Config, Kernel)\",\n",
    "    \"‚úÖ Implemented complete mathematical foundation\",\n",
    "    \"‚úÖ Created HD Kernel interface compliance\",\n",
    "    \"‚úÖ Added cryptographic integrity and versioning\",\n",
    "    \"‚úÖ Built production-ready XP Core system\",\n",
    "    \"‚úÖ Comprehensive test suite with full validation\",\n",
    "    \"‚úÖ Interactive playground for experimentation\"\n",
    "]\n",
    "\n",
    "for achievement in achievements:\n",
    "    print(f\"   {achievement}\")\n",
    "\n",
    "print(\"\\nüßÆ MATHEMATICAL FOUNDATION STATUS:\")\n",
    "print(\"-\" * 38)\n",
    "\n",
    "math_components = [\n",
    "    (\"HRR Operations (Binding/Unbinding)\", MATH_FOUNDATION_AVAILABLE),\n",
    "    (\"Memory Scoring with Temporal Decay\", MATH_FOUNDATION_AVAILABLE),\n",
    "    (\"Mathematical Coherence Computation\", MATH_FOUNDATION_AVAILABLE),\n",
    "    (\"Lexical Attribution System\", MATH_FOUNDATION_AVAILABLE),\n",
    "    (\"Circular Convolution/Correlation\", MATH_FOUNDATION_AVAILABLE),\n",
    "    (\"Vector Normalization & Stability\", MATH_FOUNDATION_AVAILABLE)\n",
    "]\n",
    "\n",
    "for component, status in math_components:\n",
    "    status_icon = \"‚úÖ\" if status else \"‚ùå\"\n",
    "    print(f\"   {status_icon} {component}\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è ARCHITECTURE STATUS:\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "architecture_components = [\n",
    "    (\"XPUnit - Fundamental unit of experience\", UNIFIED_CORE_AVAILABLE),\n",
    "    (\"XPEnvironment - Computational container\", UNIFIED_CORE_AVAILABLE),\n",
    "    (\"UnifiedXPKernel - HD Kernel interface\", UNIFIED_CORE_AVAILABLE),\n",
    "    (\"VersionedXPStore - Cryptographic storage\", VERSIONED_STORE_AVAILABLE),\n",
    "    (\"Mathematical engines (Decay, Consolidation)\", UNIFIED_CORE_AVAILABLE),\n",
    "    (\"Relationship management & spatial topology\", UNIFIED_CORE_AVAILABLE)\n",
    "]\n",
    "\n",
    "for component, status in architecture_components:\n",
    "    status_icon = \"‚úÖ\" if status else \"‚ùå\"\n",
    "    print(f\"   {status_icon} {component}\")\n",
    "\n",
    "print(\"\\nüöÄ NEXT STEPS & RECOMMENDATIONS:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "if all([UNIFIED_CORE_AVAILABLE, MATH_FOUNDATION_AVAILABLE, VERSIONED_STORE_AVAILABLE]):\n",
    "    next_steps = [\n",
    "        \"üéØ System is production-ready - start building applications!\",\n",
    "        \"üìä Run performance benchmarks with larger datasets\",\n",
    "        \"üîß Optimize embedding engines for your specific use case\",\n",
    "        \"üåê Add external integrations (databases, APIs, etc.)\",\n",
    "        \"üìö Create domain-specific memory collections\",\n",
    "        \"üß™ Experiment with different HRR dimensions and parameters\",\n",
    "        \"üìñ Build documentation and tutorials for your team\",\n",
    "        \"üîÑ Set up continuous integration and deployment\"\n",
    "    ]\n",
    "else:\n",
    "    next_steps = [\n",
    "        \"üîß Fix remaining import issues in the codebase\",\n",
    "        \"üì¶ Ensure all dependencies are properly installed\",\n",
    "        \"üß™ Run the test suite to identify specific problems\",\n",
    "        \"üìù Check the UNIFIED_CONSOLIDATION_PLAN.md for guidance\",\n",
    "        \"üíª Verify Python path and module structure\",\n",
    "        \"üîç Debug any remaining class conflicts or import errors\",\n",
    "        \"üìã Follow the step-by-step consolidation process\",\n",
    "        \"üéØ Focus on getting the mathematical foundation working first\"\n",
    "    ]\n",
    "\n",
    "for step in next_steps:\n",
    "    print(f\"   {step}\")\n",
    "\n",
    "print(\"\\nüìã USAGE EXAMPLES:\")\n",
    "print(\"-\" * 18)\n",
    "\n",
    "if hasattr(unified_kernel, 'process_memory'):\n",
    "    print(\"\\n# Basic usage examples:\")\n",
    "    print(\"# 1. Ingest new experience\")\n",
    "    print(\"content_id = unified_kernel.process_memory('Your experience here')\")\n",
    "    print(\"\")\n",
    "    print(\"# 2. Search for similar experiences\")\n",
    "    print(\"results = unified_kernel.retrieve_memory('search query', k=5)\")\n",
    "    print(\"\")\n",
    "    print(\"# 3. Apply temporal evolution\")\n",
    "    print(\"evolution_stats = unified_kernel.evolve_state(time_delta_hours=24.0)\")\n",
    "    print(\"\")\n",
    "    print(\"# 4. Get system statistics\")\n",
    "    print(\"stats = unified_kernel.get_stats()\")\n",
    "    print(\"\")\n",
    "    print(\"# 5. Export/import system state\")\n",
    "    print(\"state = unified_kernel.export_state()\")\n",
    "    print(\"success = unified_kernel.import_state(state)\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Usage examples not available - fix import issues first\")\n",
    "    print(\"\\n# Check these files:\")\n",
    "    print(\"# - src/lumina_memory/xp_core_unified.py\")\n",
    "    print(\"# - src/lumina_memory/math_foundation.py\")\n",
    "    print(\"# - src/lumina_memory/versioned_xp_store.py\")\n",
    "\n",
    "print(\"\\nüéØ FINAL STATUS:\")\n",
    "print(\"-\" * 16)\n",
    "\n",
    "total_working = sum([\n",
    "    UNIFIED_CORE_AVAILABLE,\n",
    "    MATH_FOUNDATION_AVAILABLE, \n",
    "    VERSIONED_STORE_AVAILABLE\n",
    "])\n",
    "\n",
    "if total_working == 3:\n",
    "    print(\"üéâ CONSOLIDATION SUCCESSFUL - SYSTEM FULLY OPERATIONAL!\")\n",
    "    print(\"   The unified XP Core is ready for production use.\")\n",
    "    print(\"   All mathematical foundations are working correctly.\")\n",
    "    print(\"   You can now build applications on this solid foundation.\")\n",
    "elif total_working == 2:\n",
    "    print(\"‚úÖ CONSOLIDATION MOSTLY SUCCESSFUL - MINOR ISSUES REMAIN\")\n",
    "    print(\"   Most components are working correctly.\")\n",
    "    print(\"   Fix the remaining import issue to achieve full functionality.\")\n",
    "elif total_working == 1:\n",
    "    print(\"‚ö†Ô∏è PARTIAL CONSOLIDATION - SIGNIFICANT WORK NEEDED\")\n",
    "    print(\"   Some components are working but major issues remain.\")\n",
    "    print(\"   Follow the consolidation plan to fix remaining problems.\")\n",
    "else:\n",
    "    print(\"‚ùå CONSOLIDATION INCOMPLETE - IMPORT ISSUES NEED RESOLUTION\")\n",
    "    print(\"   Focus on fixing the Python import structure first.\")\n",
    "    print(\"   Check the UNIFIED_CONSOLIDATION_PLAN.md for detailed steps.\")\n",
    "\n",
    "print(f\"\\nüìä System Readiness: {total_working}/3 components working ({total_working/3:.1%})\")\n",
    "print(\"\\n‚úÖ Unified XP Core consolidation process complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}